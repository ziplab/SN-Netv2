2022-04-03 17:40:41,332 - depth - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.1.TC455_06.29069683_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.8.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.9.0
OpenCV: 4.5.5
MMCV: 1.3.13
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
Depth: 0.0.0+4bd7d09
------------------------------------------------------------

2022-04-03 17:40:41,333 - depth - INFO - Distributed training: True
2022-04-03 17:40:41,469 - depth - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True)
model = dict(
    type='DepthEncoderDecoder',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3, 4),
        style='pytorch',
        norm_cfg=dict(type='BN', requires_grad=True),
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
    decode_head=dict(
        type='BTSHead',
        scale_up=True,
        in_channels=[64, 256, 512, 1024, 2048],
        channels=32,
        loss_decode=dict(type='SigLoss', valid_mask=True, loss_weight=1.0),
        final_norm=False,
        min_depth=0.001,
        max_depth=10),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'NYUDataset'
data_root = 'data/nyu/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (416, 544)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='DepthLoadAnnotations'),
    dict(type='NYUCrop', depth=True),
    dict(type='RandomRotate', prob=0.5, degree=2.5),
    dict(type='RandomFlip', prob=0.5),
    dict(type='RandomCrop', crop_size=(416, 544)),
    dict(
        type='ColorAug',
        prob=0.5,
        gamma_range=[0.9, 1.1],
        brightness_range=[0.75, 1.25],
        color_range=[0.9, 1.1]),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(
        type='Collect',
        keys=['img', 'depth_gt'],
        meta_keys=('filename', 'ori_filename', 'ori_shape', 'img_shape',
                   'pad_shape', 'scale_factor', 'flip', 'flip_direction',
                   'img_norm_cfg', 'cam_intrinsic'))
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(480, 640),
        flip=True,
        flip_direction='horizontal',
        transforms=[
            dict(type='RandomFlip', direction='horizontal'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=('filename', 'ori_filename', 'ori_shape',
                           'img_shape', 'pad_shape', 'scale_factor', 'flip',
                           'flip_direction', 'img_norm_cfg', 'cam_intrinsic'))
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=8,
    train=dict(
        type='NYUDataset',
        data_root='data/nyu/',
        depth_scale=1000,
        split='nyu_train.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='DepthLoadAnnotations'),
            dict(type='NYUCrop', depth=True),
            dict(type='RandomRotate', prob=0.5, degree=2.5),
            dict(type='RandomFlip', prob=0.5),
            dict(type='RandomCrop', crop_size=(416, 544)),
            dict(
                type='ColorAug',
                prob=0.5,
                gamma_range=[0.9, 1.1],
                brightness_range=[0.75, 1.25],
                color_range=[0.9, 1.1]),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'depth_gt'],
                meta_keys=('filename', 'ori_filename', 'ori_shape',
                           'img_shape', 'pad_shape', 'scale_factor', 'flip',
                           'flip_direction', 'img_norm_cfg', 'cam_intrinsic'))
        ],
        garg_crop=False,
        eigen_crop=True,
        min_depth=0.001,
        max_depth=10),
    val=dict(
        type='NYUDataset',
        data_root='data/nyu/',
        depth_scale=1000,
        split='nyu_test.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(480, 640),
                flip=True,
                flip_direction='horizontal',
                transforms=[
                    dict(type='RandomFlip', direction='horizontal'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=('filename', 'ori_filename', 'ori_shape',
                                   'img_shape', 'pad_shape', 'scale_factor',
                                   'flip', 'flip_direction', 'img_norm_cfg',
                                   'cam_intrinsic'))
                ])
        ],
        garg_crop=False,
        eigen_crop=True,
        min_depth=0.001,
        max_depth=10),
    test=dict(
        type='NYUDataset',
        data_root='data/nyu/',
        depth_scale=1000,
        split='nyu_test.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(480, 640),
                flip=True,
                flip_direction='horizontal',
                transforms=[
                    dict(type='RandomFlip', direction='horizontal'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=('filename', 'ori_filename', 'ori_shape',
                                   'img_shape', 'pad_shape', 'scale_factor',
                                   'flip', 'flip_direction', 'img_norm_cfg',
                                   'cam_intrinsic'))
                ])
        ],
        garg_crop=False,
        eigen_crop=True,
        min_depth=0.001,
        max_depth=10))
log_config = dict(
    interval=50,
    hooks=[
        dict(type='TextLoggerHook', by_epoch=True),
        dict(type='TensorboardImageLoggerHook', by_epoch=True)
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
max_lr = 0.0001
optimizer = dict(
    type='AdamW', lr=0.0001, betas=(0.95, 0.99), weight_decay=0.01)
lr_config = dict(
    policy='OneCycle',
    max_lr=0.0001,
    div_factor=25,
    final_div_factor=100,
    by_epoch=False)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
runner = dict(type='EpochBasedRunner', max_epochs=24)
checkpoint_config = dict(by_epoch=True, max_keep_ckpts=2, interval=1)
evaluation = dict(by_epoch=True, interval=6, pre_eval=True)
work_dir = 'nfs/saves/bts/bts_r50_nyu'
gpu_ids = range(0, 1)

2022-04-03 17:40:41,676 - depth - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

decode_head.conv_depth.weight - torch.Size([1, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.conv_depth.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.upconv5.conv.weight - torch.Size([512, 2048, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn5.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.conv5.0.weight - torch.Size([512, 1536, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.upconv4.conv.weight - torch.Size([256, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.conv4.0.weight - torch.Size([256, 768, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn4_2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn4_2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_3.atrous_conv.aconv_sequence.1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_3.atrous_conv.aconv_sequence.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_3.atrous_conv.aconv_sequence.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_3.atrous_conv.aconv_sequence.4.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_6.atrous_conv.first_bn.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_6.atrous_conv.first_bn.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_6.atrous_conv.aconv_sequence.1.weight - torch.Size([256, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_6.atrous_conv.aconv_sequence.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_6.atrous_conv.aconv_sequence.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_6.atrous_conv.aconv_sequence.4.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_12.atrous_conv.first_bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_12.atrous_conv.first_bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_12.atrous_conv.aconv_sequence.1.weight - torch.Size([256, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_12.atrous_conv.aconv_sequence.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_12.atrous_conv.aconv_sequence.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_12.atrous_conv.aconv_sequence.4.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_18.atrous_conv.first_bn.weight - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_18.atrous_conv.first_bn.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_18.atrous_conv.aconv_sequence.1.weight - torch.Size([256, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_18.atrous_conv.aconv_sequence.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_18.atrous_conv.aconv_sequence.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_18.atrous_conv.aconv_sequence.4.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_24.atrous_conv.first_bn.weight - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_24.atrous_conv.first_bn.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_24.atrous_conv.aconv_sequence.1.weight - torch.Size([256, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_24.atrous_conv.aconv_sequence.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_24.atrous_conv.aconv_sequence.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_24.atrous_conv.aconv_sequence.4.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.daspp_conv.0.weight - torch.Size([128, 896, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc8x8.reduc.inter_128_128.0.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc8x8.reduc.inter_128_64.0.weight - torch.Size([64, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc8x8.reduc.inter_64_32.0.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc8x8.reduc.inter_32_16.0.weight - torch.Size([16, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc8x8.reduc.inter_16_8.0.weight - torch.Size([8, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc8x8.reduc.plane_params.weight - torch.Size([3, 8, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.upconv3.conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn3.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.conv3.0.weight - torch.Size([128, 385, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc4x4.reduc.inter_128_64.0.weight - torch.Size([64, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc4x4.reduc.inter_64_32.0.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc4x4.reduc.inter_32_16.0.weight - torch.Size([16, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc4x4.reduc.inter_16_8.0.weight - torch.Size([8, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc4x4.reduc.plane_params.weight - torch.Size([3, 8, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.upconv2.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.conv2.0.weight - torch.Size([64, 129, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc2x2.reduc.inter_64_32.0.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc2x2.reduc.inter_32_16.0.weight - torch.Size([16, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc2x2.reduc.inter_16_8.0.weight - torch.Size([8, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc2x2.reduc.plane_params.weight - torch.Size([3, 8, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.upconv1.conv.weight - torch.Size([32, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc1x1.reduc.inter_32_16.0.weight - torch.Size([16, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc1x1.reduc.inter_16_8.0.weight - torch.Size([8, 16, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.reduc1x1.reduc.final.0.weight - torch.Size([1, 8, 1, 1]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  

decode_head.conv1.0.weight - torch.Size([32, 36, 3, 3]): 
The value is the same before and after calling `init_weights` of DepthEncoderDecoder  
2022-04-03 17:40:43,243 - depth - INFO - DepthEncoderDecoder(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
  (decode_head): BTSHead(
    align_corners=False
    (loss_decode): SigLoss()
    (conv_depth): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu): ReLU()
    (sigmoid): Sigmoid()
    (upconv5): upconv(
      (elu): ELU(alpha=1.0)
      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn5): BatchNorm2d(512, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
    (conv5): Sequential(
      (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ELU(alpha=1.0)
    )
    (upconv4): upconv(
      (elu): ELU(alpha=1.0)
      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn4): BatchNorm2d(256, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
    (conv4): Sequential(
      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ELU(alpha=1.0)
    )
    (bn4_2): BatchNorm2d(256, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
    (daspp_3): atrous_conv(
      (atrous_conv): Sequential(
        (aconv_sequence): Sequential(
          (0): ReLU()
          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)
        )
      )
    )
    (daspp_6): atrous_conv(
      (atrous_conv): Sequential(
        (first_bn): BatchNorm2d(896, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
        (aconv_sequence): Sequential(
          (0): ReLU()
          (1): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
        )
      )
    )
    (daspp_12): atrous_conv(
      (atrous_conv): Sequential(
        (first_bn): BatchNorm2d(1024, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
        (aconv_sequence): Sequential(
          (0): ReLU()
          (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
        )
      )
    )
    (daspp_18): atrous_conv(
      (atrous_conv): Sequential(
        (first_bn): BatchNorm2d(1152, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
        (aconv_sequence): Sequential(
          (0): ReLU()
          (1): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
        )
      )
    )
    (daspp_24): atrous_conv(
      (atrous_conv): Sequential(
        (first_bn): BatchNorm2d(1280, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
        (aconv_sequence): Sequential(
          (0): ReLU()
          (1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          (3): ReLU()
          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)
        )
      )
    )
    (daspp_conv): Sequential(
      (0): Conv2d(896, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ELU(alpha=1.0)
    )
    (reduc8x8): reduction_1x1(
      (sigmoid): Sigmoid()
      (reduc): Sequential(
        (inter_128_128): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_128_64): Sequential(
          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_64_32): Sequential(
          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_32_16): Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_16_8): Sequential(
          (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (plane_params): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
    )
    (lpg8x8): local_planar_guidance()
    (upconv3): upconv(
      (elu): ELU(alpha=1.0)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn3): BatchNorm2d(128, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
    (conv3): Sequential(
      (0): Conv2d(385, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ELU(alpha=1.0)
    )
    (reduc4x4): reduction_1x1(
      (sigmoid): Sigmoid()
      (reduc): Sequential(
        (inter_128_64): Sequential(
          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_64_32): Sequential(
          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_32_16): Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_16_8): Sequential(
          (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (plane_params): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
    )
    (lpg4x4): local_planar_guidance()
    (upconv2): upconv(
      (elu): ELU(alpha=1.0)
      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn2): BatchNorm2d(64, eps=1.1e-05, momentum=0.01, affine=True, track_running_stats=True)
    (conv2): Sequential(
      (0): Conv2d(129, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ELU(alpha=1.0)
    )
    (reduc2x2): reduction_1x1(
      (sigmoid): Sigmoid()
      (reduc): Sequential(
        (inter_64_32): Sequential(
          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_32_16): Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_16_8): Sequential(
          (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (plane_params): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
    )
    (lpg2x2): local_planar_guidance()
    (upconv1): upconv(
      (elu): ELU(alpha=1.0)
      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (reduc1x1): reduction_1x1(
      (sigmoid): Sigmoid()
      (reduc): Sequential(
        (inter_32_16): Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (inter_16_8): Sequential(
          (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ELU(alpha=1.0)
        )
        (final): Sequential(
          (0): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Sigmoid()
        )
      )
    )
    (conv1): Sequential(
      (0): Conv2d(36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ELU(alpha=1.0)
    )
  )
)
2022-04-03 17:40:43,358 - depth - INFO - Loaded 24231 images. Totally 0 invalid pairs are filtered
2022-04-03 17:40:43,831 - depth - INFO - Loaded 654 images. Totally 0 invalid pairs are filtered
2022-04-03 17:40:43,831 - depth - INFO - Start running, host: zhyever@zhyever-System-Product-Name, work_dir: /home/zhyever/zhenyuli/code/Monocular-Depth-Estimation-Toolbox/nfs/saves/bts/bts_r50_nyu
2022-04-03 17:40:43,831 - depth - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) OneCycleLrUpdaterHook              
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) OneCycleLrUpdaterHook              
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
before_train_iter:
(VERY_HIGH   ) OneCycleLrUpdaterHook              
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardImageLoggerHook         
 -------------------- 
2022-04-03 17:40:43,831 - depth - INFO - workflow: [('train', 1)], max: 24 epochs
2022-04-03 17:41:31,290 - depth - INFO - Epoch [1][50/1514]	lr: 4.005e-06, eta: 9:33:15, time: 0.948, data_time: 0.430, memory: 15394, decode.loss_depth: 0.4720, loss: 0.4720, grad_norm: 1.0032
2022-04-03 17:41:48,983 - depth - INFO - Epoch [1][100/1514]	lr: 4.020e-06, eta: 6:33:05, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.4166, loss: 0.4166, grad_norm: 1.3963
2022-04-03 17:42:06,725 - depth - INFO - Epoch [1][150/1514]	lr: 4.044e-06, eta: 5:33:01, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.3830, loss: 0.3830, grad_norm: 1.6987
2022-04-03 17:42:24,483 - depth - INFO - Epoch [1][200/1514]	lr: 4.079e-06, eta: 5:02:54, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.3456, loss: 0.3456, grad_norm: 2.0659
2022-04-03 17:42:42,241 - depth - INFO - Epoch [1][250/1514]	lr: 4.124e-06, eta: 4:44:42, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.3182, loss: 0.3182, grad_norm: 2.2648
2022-04-03 17:43:00,002 - depth - INFO - Epoch [1][300/1514]	lr: 4.178e-06, eta: 4:32:29, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2969, loss: 0.2969, grad_norm: 2.3809
2022-04-03 17:43:17,787 - depth - INFO - Epoch [1][350/1514]	lr: 4.243e-06, eta: 4:23:42, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2874, loss: 0.2874, grad_norm: 2.3839
2022-04-03 17:43:35,594 - depth - INFO - Epoch [1][400/1514]	lr: 4.317e-06, eta: 4:17:05, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2645, loss: 0.2645, grad_norm: 2.5694
2022-04-03 17:43:53,337 - depth - INFO - Epoch [1][450/1514]	lr: 4.401e-06, eta: 4:11:47, time: 0.355, data_time: 0.006, memory: 15394, decode.loss_depth: 0.2632, loss: 0.2632, grad_norm: 2.5700
2022-04-03 17:44:11,093 - depth - INFO - Epoch [1][500/1514]	lr: 4.496e-06, eta: 4:07:30, time: 0.355, data_time: 0.007, memory: 15394, decode.loss_depth: 0.2586, loss: 0.2586, grad_norm: 2.5109
2022-04-03 17:44:28,912 - depth - INFO - Epoch [1][550/1514]	lr: 4.600e-06, eta: 4:04:00, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2519, loss: 0.2519, grad_norm: 2.4696
2022-04-03 17:44:46,713 - depth - INFO - Epoch [1][600/1514]	lr: 4.714e-06, eta: 4:01:02, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2445, loss: 0.2445, grad_norm: 2.4691
2022-04-03 17:45:04,533 - depth - INFO - Epoch [1][650/1514]	lr: 4.837e-06, eta: 3:58:29, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2456, loss: 0.2456, grad_norm: 2.3826
2022-04-03 17:45:22,283 - depth - INFO - Epoch [1][700/1514]	lr: 4.971e-06, eta: 3:56:12, time: 0.355, data_time: 0.007, memory: 15394, decode.loss_depth: 0.2398, loss: 0.2398, grad_norm: 2.5805
2022-04-03 17:45:40,101 - depth - INFO - Epoch [1][750/1514]	lr: 5.114e-06, eta: 3:54:14, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2315, loss: 0.2315, grad_norm: 2.4640
2022-04-03 17:45:57,886 - depth - INFO - Epoch [1][800/1514]	lr: 5.267e-06, eta: 3:52:27, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2355, loss: 0.2355, grad_norm: 2.5176
2022-04-03 17:46:15,686 - depth - INFO - Epoch [1][850/1514]	lr: 5.430e-06, eta: 3:50:51, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2308, loss: 0.2308, grad_norm: 2.4809
2022-04-03 17:46:33,512 - depth - INFO - Epoch [1][900/1514]	lr: 5.602e-06, eta: 3:49:25, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2289, loss: 0.2289, grad_norm: 2.5276
2022-04-03 17:46:51,354 - depth - INFO - Epoch [1][950/1514]	lr: 5.784e-06, eta: 3:48:07, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2247, loss: 0.2247, grad_norm: 2.5425
2022-04-03 17:47:09,139 - depth - INFO - Exp name: bts_r50_nyu_24e.py
2022-04-03 17:47:09,140 - depth - INFO - Epoch [1][1000/1514]	lr: 5.976e-06, eta: 3:46:52, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.2254, loss: 0.2254, grad_norm: 2.6406
2022-04-03 17:47:26,938 - depth - INFO - Epoch [1][1050/1514]	lr: 6.177e-06, eta: 3:45:44, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2204, loss: 0.2204, grad_norm: 2.6691
2022-04-03 17:47:44,730 - depth - INFO - Epoch [1][1100/1514]	lr: 6.388e-06, eta: 3:44:40, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2221, loss: 0.2221, grad_norm: 2.6990
2022-04-03 17:48:02,559 - depth - INFO - Epoch [1][1150/1514]	lr: 6.608e-06, eta: 3:43:41, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2178, loss: 0.2178, grad_norm: 2.5562
2022-04-03 17:48:20,385 - depth - INFO - Epoch [1][1200/1514]	lr: 6.838e-06, eta: 3:42:45, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2132, loss: 0.2132, grad_norm: 2.4114
2022-04-03 17:48:38,201 - depth - INFO - Epoch [1][1250/1514]	lr: 7.077e-06, eta: 3:41:53, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2132, loss: 0.2132, grad_norm: 2.4389
2022-04-03 17:48:55,961 - depth - INFO - Epoch [1][1300/1514]	lr: 7.325e-06, eta: 3:41:01, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2082, loss: 0.2082, grad_norm: 2.5801
2022-04-03 17:49:13,752 - depth - INFO - Epoch [1][1350/1514]	lr: 7.583e-06, eta: 3:40:13, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2100, loss: 0.2100, grad_norm: 2.4628
2022-04-03 17:49:31,575 - depth - INFO - Epoch [1][1400/1514]	lr: 7.850e-06, eta: 3:39:27, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.2086, loss: 0.2086, grad_norm: 2.3795
2022-04-03 17:49:49,365 - depth - INFO - Epoch [1][1450/1514]	lr: 8.126e-06, eta: 3:38:43, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.2043, loss: 0.2043, grad_norm: 2.4212
2022-04-03 17:50:07,151 - depth - INFO - Epoch [1][1500/1514]	lr: 8.411e-06, eta: 3:38:00, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1982, loss: 0.1982, grad_norm: 2.3372
2022-04-03 17:50:12,242 - depth - INFO - Saving checkpoint at 1 epochs
2022-04-03 17:50:32,658 - depth - INFO - Epoch [2][50/1514]	lr: 8.789e-06, eta: 3:36:04, time: 0.397, data_time: 0.048, memory: 15394, decode.loss_depth: 0.2009, loss: 0.2009, grad_norm: 2.2612
2022-04-03 17:50:50,501 - depth - INFO - Epoch [2][100/1514]	lr: 9.095e-06, eta: 3:35:28, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1982, loss: 0.1982, grad_norm: 2.3391
2022-04-03 17:51:08,294 - depth - INFO - Epoch [2][150/1514]	lr: 9.409e-06, eta: 3:34:52, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.2015, loss: 0.2015, grad_norm: 2.4624
2022-04-03 17:51:26,089 - depth - INFO - Epoch [2][200/1514]	lr: 9.733e-06, eta: 3:34:18, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1982, loss: 0.1982, grad_norm: 2.2813
2022-04-03 17:51:43,895 - depth - INFO - Epoch [2][250/1514]	lr: 1.006e-05, eta: 3:33:44, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1926, loss: 0.1926, grad_norm: 2.3693
2022-04-03 17:52:01,728 - depth - INFO - Epoch [2][300/1514]	lr: 1.041e-05, eta: 3:33:12, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1874, loss: 0.1874, grad_norm: 2.2659
2022-04-03 17:52:19,588 - depth - INFO - Epoch [2][350/1514]	lr: 1.076e-05, eta: 3:32:41, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1882, loss: 0.1882, grad_norm: 2.2008
2022-04-03 17:52:37,396 - depth - INFO - Epoch [2][400/1514]	lr: 1.111e-05, eta: 3:32:10, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1844, loss: 0.1844, grad_norm: 2.3828
2022-04-03 17:52:55,116 - depth - INFO - Epoch [2][450/1514]	lr: 1.148e-05, eta: 3:31:38, time: 0.354, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1920, loss: 0.1920, grad_norm: 2.3866
2022-04-03 17:53:12,918 - depth - INFO - Epoch [2][500/1514]	lr: 1.185e-05, eta: 3:31:08, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1865, loss: 0.1865, grad_norm: 2.2354
2022-04-03 17:53:30,729 - depth - INFO - Epoch [2][550/1514]	lr: 1.224e-05, eta: 3:30:39, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1886, loss: 0.1886, grad_norm: 2.3120
2022-04-03 17:53:48,550 - depth - INFO - Epoch [2][600/1514]	lr: 1.263e-05, eta: 3:30:10, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1804, loss: 0.1804, grad_norm: 2.1061
2022-04-03 17:54:06,390 - depth - INFO - Epoch [2][650/1514]	lr: 1.303e-05, eta: 3:29:43, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1829, loss: 0.1829, grad_norm: 2.0200
2022-04-03 17:54:24,167 - depth - INFO - Epoch [2][700/1514]	lr: 1.344e-05, eta: 3:29:14, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1811, loss: 0.1811, grad_norm: 2.2367
2022-04-03 17:54:42,005 - depth - INFO - Epoch [2][750/1514]	lr: 1.385e-05, eta: 3:28:48, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1749, loss: 0.1749, grad_norm: 1.9763
2022-04-03 17:54:59,849 - depth - INFO - Epoch [2][800/1514]	lr: 1.428e-05, eta: 3:28:21, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1763, loss: 0.1763, grad_norm: 1.9824
2022-04-03 17:55:17,663 - depth - INFO - Epoch [2][850/1514]	lr: 1.471e-05, eta: 3:27:55, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1736, loss: 0.1736, grad_norm: 2.2002
2022-04-03 17:55:35,482 - depth - INFO - Epoch [2][900/1514]	lr: 1.515e-05, eta: 3:27:29, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1721, loss: 0.1721, grad_norm: 2.2344
2022-04-03 17:55:53,305 - depth - INFO - Epoch [2][950/1514]	lr: 1.560e-05, eta: 3:27:03, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1719, loss: 0.1719, grad_norm: 1.9656
2022-04-03 17:56:11,075 - depth - INFO - Epoch [2][1000/1514]	lr: 1.605e-05, eta: 3:26:37, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1759, loss: 0.1759, grad_norm: 2.2221
2022-04-03 17:56:28,857 - depth - INFO - Epoch [2][1050/1514]	lr: 1.651e-05, eta: 3:26:12, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1716, loss: 0.1716, grad_norm: 2.0482
2022-04-03 17:56:46,621 - depth - INFO - Epoch [2][1100/1514]	lr: 1.698e-05, eta: 3:25:46, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1724, loss: 0.1724, grad_norm: 2.1811
2022-04-03 17:57:04,419 - depth - INFO - Epoch [2][1150/1514]	lr: 1.746e-05, eta: 3:25:22, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1708, loss: 0.1708, grad_norm: 2.2126
2022-04-03 17:57:22,223 - depth - INFO - Epoch [2][1200/1514]	lr: 1.794e-05, eta: 3:24:57, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1663, loss: 0.1663, grad_norm: 1.9424
2022-04-03 17:57:40,037 - depth - INFO - Epoch [2][1250/1514]	lr: 1.843e-05, eta: 3:24:33, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1670, loss: 0.1670, grad_norm: 1.8463
2022-04-03 17:57:57,842 - depth - INFO - Epoch [2][1300/1514]	lr: 1.893e-05, eta: 3:24:09, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1664, loss: 0.1664, grad_norm: 2.0033
2022-04-03 17:58:15,671 - depth - INFO - Epoch [2][1350/1514]	lr: 1.944e-05, eta: 3:23:46, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1673, loss: 0.1673, grad_norm: 1.9460
2022-04-03 17:58:33,542 - depth - INFO - Epoch [2][1400/1514]	lr: 1.995e-05, eta: 3:23:23, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1665, loss: 0.1665, grad_norm: 1.9915
2022-04-03 17:58:51,366 - depth - INFO - Epoch [2][1450/1514]	lr: 2.047e-05, eta: 3:23:00, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1656, loss: 0.1656, grad_norm: 2.0795
2022-04-03 17:59:09,175 - depth - INFO - Epoch [2][1500/1514]	lr: 2.099e-05, eta: 3:22:37, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1602, loss: 0.1602, grad_norm: 1.9321
2022-04-03 17:59:14,239 - depth - INFO - Saving checkpoint at 2 epochs
2022-04-03 17:59:34,623 - depth - INFO - Epoch [3][50/1514]	lr: 2.167e-05, eta: 3:21:35, time: 0.396, data_time: 0.049, memory: 15394, decode.loss_depth: 0.1604, loss: 0.1604, grad_norm: 1.7911
2022-04-03 17:59:52,419 - depth - INFO - Epoch [3][100/1514]	lr: 2.221e-05, eta: 3:21:13, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1611, loss: 0.1611, grad_norm: 1.8633
2022-04-03 18:00:10,230 - depth - INFO - Epoch [3][150/1514]	lr: 2.276e-05, eta: 3:20:51, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1620, loss: 0.1620, grad_norm: 1.9211
2022-04-03 18:00:28,079 - depth - INFO - Epoch [3][200/1514]	lr: 2.331e-05, eta: 3:20:29, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1686, loss: 0.1686, grad_norm: 2.1673
2022-04-03 18:00:45,888 - depth - INFO - Epoch [3][250/1514]	lr: 2.387e-05, eta: 3:20:08, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1546, loss: 0.1546, grad_norm: 1.5920
2022-04-03 18:01:03,686 - depth - INFO - Epoch [3][300/1514]	lr: 2.443e-05, eta: 3:19:46, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1537, loss: 0.1537, grad_norm: 1.6880
2022-04-03 18:01:21,492 - depth - INFO - Epoch [3][350/1514]	lr: 2.500e-05, eta: 3:19:24, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1553, loss: 0.1553, grad_norm: 1.6956
2022-04-03 18:01:39,294 - depth - INFO - Epoch [3][400/1514]	lr: 2.557e-05, eta: 3:19:03, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1543, loss: 0.1543, grad_norm: 1.9217
2022-04-03 18:01:57,090 - depth - INFO - Epoch [3][450/1514]	lr: 2.615e-05, eta: 3:18:41, time: 0.356, data_time: 0.006, memory: 15394, decode.loss_depth: 0.1557, loss: 0.1557, grad_norm: 1.8015
2022-04-03 18:02:14,942 - depth - INFO - Epoch [3][500/1514]	lr: 2.674e-05, eta: 3:18:20, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1529, loss: 0.1529, grad_norm: 1.6303
2022-04-03 18:02:32,792 - depth - INFO - Epoch [3][550/1514]	lr: 2.733e-05, eta: 3:18:00, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1505, loss: 0.1505, grad_norm: 1.5995
2022-04-03 18:02:50,637 - depth - INFO - Epoch [3][600/1514]	lr: 2.792e-05, eta: 3:17:39, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1488, loss: 0.1488, grad_norm: 1.6297
2022-04-03 18:03:08,497 - depth - INFO - Epoch [3][650/1514]	lr: 2.853e-05, eta: 3:17:18, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1504, loss: 0.1504, grad_norm: 1.5376
2022-04-03 18:03:26,315 - depth - INFO - Epoch [3][700/1514]	lr: 2.913e-05, eta: 3:16:58, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1499, loss: 0.1499, grad_norm: 1.6453
2022-04-03 18:03:44,145 - depth - INFO - Epoch [3][750/1514]	lr: 2.974e-05, eta: 3:16:37, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1484, loss: 0.1484, grad_norm: 1.6668
2022-04-03 18:04:01,982 - depth - INFO - Epoch [3][800/1514]	lr: 3.036e-05, eta: 3:16:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1500, loss: 0.1500, grad_norm: 1.7175
2022-04-03 18:04:19,802 - depth - INFO - Epoch [3][850/1514]	lr: 3.098e-05, eta: 3:15:56, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1515, loss: 0.1515, grad_norm: 2.0353
2022-04-03 18:04:37,608 - depth - INFO - Epoch [3][900/1514]	lr: 3.160e-05, eta: 3:15:35, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1460, loss: 0.1460, grad_norm: 1.7070
2022-04-03 18:04:55,449 - depth - INFO - Epoch [3][950/1514]	lr: 3.223e-05, eta: 3:15:15, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1472, loss: 0.1472, grad_norm: 1.5077
2022-04-03 18:05:13,285 - depth - INFO - Epoch [3][1000/1514]	lr: 3.286e-05, eta: 3:14:55, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1513, loss: 0.1513, grad_norm: 1.8188
2022-04-03 18:05:31,096 - depth - INFO - Epoch [3][1050/1514]	lr: 3.350e-05, eta: 3:14:34, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1462, loss: 0.1462, grad_norm: 1.6442
2022-04-03 18:05:48,881 - depth - INFO - Epoch [3][1100/1514]	lr: 3.414e-05, eta: 3:14:14, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1476, loss: 0.1476, grad_norm: 1.8188
2022-04-03 18:06:06,678 - depth - INFO - Epoch [3][1150/1514]	lr: 3.478e-05, eta: 3:13:54, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1449, loss: 0.1449, grad_norm: 1.7224
2022-04-03 18:06:24,489 - depth - INFO - Epoch [3][1200/1514]	lr: 3.543e-05, eta: 3:13:33, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1408, loss: 0.1408, grad_norm: 1.5116
2022-04-03 18:06:42,271 - depth - INFO - Epoch [3][1250/1514]	lr: 3.608e-05, eta: 3:13:13, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1468, loss: 0.1468, grad_norm: 1.7981
2022-04-03 18:07:00,081 - depth - INFO - Epoch [3][1300/1514]	lr: 3.673e-05, eta: 3:12:53, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1413, loss: 0.1413, grad_norm: 1.5921
2022-04-03 18:07:17,925 - depth - INFO - Epoch [3][1350/1514]	lr: 3.739e-05, eta: 3:12:33, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1431, loss: 0.1431, grad_norm: 1.4814
2022-04-03 18:07:35,741 - depth - INFO - Epoch [3][1400/1514]	lr: 3.805e-05, eta: 3:12:13, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1440, loss: 0.1440, grad_norm: 1.5030
2022-04-03 18:07:53,515 - depth - INFO - Epoch [3][1450/1514]	lr: 3.872e-05, eta: 3:11:53, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1493, loss: 0.1493, grad_norm: 1.8389
2022-04-03 18:08:11,361 - depth - INFO - Epoch [3][1500/1514]	lr: 3.938e-05, eta: 3:11:33, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1399, loss: 0.1399, grad_norm: 1.5452
2022-04-03 18:08:16,453 - depth - INFO - Saving checkpoint at 3 epochs
2022-04-03 18:08:36,833 - depth - INFO - Epoch [4][50/1514]	lr: 4.024e-05, eta: 3:10:47, time: 0.396, data_time: 0.048, memory: 15394, decode.loss_depth: 0.1400, loss: 0.1400, grad_norm: 1.4991
2022-04-03 18:08:54,611 - depth - INFO - Epoch [4][100/1514]	lr: 4.091e-05, eta: 3:10:27, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1381, loss: 0.1381, grad_norm: 1.5178
2022-04-03 18:09:12,409 - depth - INFO - Epoch [4][150/1514]	lr: 4.158e-05, eta: 3:10:08, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1412, loss: 0.1412, grad_norm: 1.5171
2022-04-03 18:09:30,188 - depth - INFO - Epoch [4][200/1514]	lr: 4.226e-05, eta: 3:09:48, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1477, loss: 0.1477, grad_norm: 1.8463
2022-04-03 18:09:47,979 - depth - INFO - Epoch [4][250/1514]	lr: 4.294e-05, eta: 3:09:29, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1361, loss: 0.1361, grad_norm: 1.3862
2022-04-03 18:10:05,750 - depth - INFO - Epoch [4][300/1514]	lr: 4.362e-05, eta: 3:09:09, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1344, loss: 0.1344, grad_norm: 1.4305
2022-04-03 18:10:23,548 - depth - INFO - Epoch [4][350/1514]	lr: 4.430e-05, eta: 3:08:49, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1357, loss: 0.1357, grad_norm: 1.3799
2022-04-03 18:10:41,358 - depth - INFO - Epoch [4][400/1514]	lr: 4.498e-05, eta: 3:08:30, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1356, loss: 0.1356, grad_norm: 1.6584
2022-04-03 18:10:59,121 - depth - INFO - Epoch [4][450/1514]	lr: 4.567e-05, eta: 3:08:11, time: 0.355, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1363, loss: 0.1363, grad_norm: 1.4593
2022-04-03 18:11:16,948 - depth - INFO - Epoch [4][500/1514]	lr: 4.636e-05, eta: 3:07:51, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1326, loss: 0.1326, grad_norm: 1.4300
2022-04-03 18:11:34,771 - depth - INFO - Epoch [4][550/1514]	lr: 4.704e-05, eta: 3:07:32, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1338, loss: 0.1338, grad_norm: 1.3695
2022-04-03 18:11:52,621 - depth - INFO - Epoch [4][600/1514]	lr: 4.773e-05, eta: 3:07:13, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1331, loss: 0.1331, grad_norm: 1.4024
2022-04-03 18:12:10,499 - depth - INFO - Epoch [4][650/1514]	lr: 4.842e-05, eta: 3:06:54, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1344, loss: 0.1344, grad_norm: 1.3316
2022-04-03 18:12:28,289 - depth - INFO - Epoch [4][700/1514]	lr: 4.911e-05, eta: 3:06:35, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1325, loss: 0.1325, grad_norm: 1.4618
2022-04-03 18:12:46,117 - depth - INFO - Epoch [4][750/1514]	lr: 4.980e-05, eta: 3:06:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1293, loss: 0.1293, grad_norm: 1.3777
2022-04-03 18:13:03,919 - depth - INFO - Epoch [4][800/1514]	lr: 5.049e-05, eta: 3:05:57, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1307, loss: 0.1307, grad_norm: 1.3647
2022-04-03 18:13:21,675 - depth - INFO - Epoch [4][850/1514]	lr: 5.119e-05, eta: 3:05:38, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1295, loss: 0.1295, grad_norm: 1.3723
2022-04-03 18:13:39,453 - depth - INFO - Epoch [4][900/1514]	lr: 5.188e-05, eta: 3:05:18, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1319, loss: 0.1319, grad_norm: 1.6410
2022-04-03 18:13:57,312 - depth - INFO - Epoch [4][950/1514]	lr: 5.257e-05, eta: 3:05:00, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1309, loss: 0.1309, grad_norm: 1.3626
2022-04-03 18:14:15,139 - depth - INFO - Epoch [4][1000/1514]	lr: 5.326e-05, eta: 3:04:41, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1336, loss: 0.1336, grad_norm: 1.5402
2022-04-03 18:14:32,954 - depth - INFO - Epoch [4][1050/1514]	lr: 5.395e-05, eta: 3:04:22, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1339, loss: 0.1339, grad_norm: 1.4447
2022-04-03 18:14:50,765 - depth - INFO - Epoch [4][1100/1514]	lr: 5.464e-05, eta: 3:04:03, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1325, loss: 0.1325, grad_norm: 1.3985
2022-04-03 18:15:08,563 - depth - INFO - Epoch [4][1150/1514]	lr: 5.533e-05, eta: 3:03:44, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1326, loss: 0.1326, grad_norm: 1.6090
2022-04-03 18:15:26,416 - depth - INFO - Epoch [4][1200/1514]	lr: 5.602e-05, eta: 3:03:25, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1261, loss: 0.1261, grad_norm: 1.3278
2022-04-03 18:15:44,263 - depth - INFO - Epoch [4][1250/1514]	lr: 5.671e-05, eta: 3:03:06, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1281, loss: 0.1281, grad_norm: 1.3883
2022-04-03 18:16:02,052 - depth - INFO - Epoch [4][1300/1514]	lr: 5.740e-05, eta: 3:02:47, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1284, loss: 0.1284, grad_norm: 1.2942
2022-04-03 18:16:19,851 - depth - INFO - Epoch [4][1350/1514]	lr: 5.809e-05, eta: 3:02:28, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1304, loss: 0.1304, grad_norm: 1.4802
2022-04-03 18:16:37,655 - depth - INFO - Epoch [4][1400/1514]	lr: 5.877e-05, eta: 3:02:09, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1289, loss: 0.1289, grad_norm: 1.2634
2022-04-03 18:16:55,420 - depth - INFO - Epoch [4][1450/1514]	lr: 5.946e-05, eta: 3:01:50, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1281, loss: 0.1281, grad_norm: 1.3915
2022-04-03 18:17:13,182 - depth - INFO - Epoch [4][1500/1514]	lr: 6.014e-05, eta: 3:01:31, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1227, loss: 0.1227, grad_norm: 1.3027
2022-04-03 18:17:18,263 - depth - INFO - Saving checkpoint at 4 epochs
2022-04-03 18:17:38,628 - depth - INFO - Epoch [5][50/1514]	lr: 6.101e-05, eta: 3:00:52, time: 0.395, data_time: 0.047, memory: 15394, decode.loss_depth: 0.1258, loss: 0.1258, grad_norm: 1.3046
2022-04-03 18:17:56,433 - depth - INFO - Epoch [5][100/1514]	lr: 6.169e-05, eta: 3:00:33, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1271, loss: 0.1271, grad_norm: 1.2116
2022-04-03 18:18:14,210 - depth - INFO - Epoch [5][150/1514]	lr: 6.236e-05, eta: 3:00:15, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1248, loss: 0.1248, grad_norm: 1.2801
2022-04-03 18:18:32,029 - depth - INFO - Epoch [5][200/1514]	lr: 6.304e-05, eta: 2:59:56, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1288, loss: 0.1288, grad_norm: 1.3594
2022-04-03 18:18:49,835 - depth - INFO - Epoch [5][250/1514]	lr: 6.371e-05, eta: 2:59:38, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1227, loss: 0.1227, grad_norm: 1.3017
2022-04-03 18:19:07,618 - depth - INFO - Epoch [5][300/1514]	lr: 6.438e-05, eta: 2:59:19, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1218, loss: 0.1218, grad_norm: 1.2768
2022-04-03 18:19:25,422 - depth - INFO - Epoch [5][350/1514]	lr: 6.505e-05, eta: 2:59:00, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1219, loss: 0.1219, grad_norm: 1.2019
2022-04-03 18:19:43,172 - depth - INFO - Epoch [5][400/1514]	lr: 6.571e-05, eta: 2:58:41, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1182, loss: 0.1182, grad_norm: 1.2042
2022-04-03 18:20:00,890 - depth - INFO - Epoch [5][450/1514]	lr: 6.637e-05, eta: 2:58:22, time: 0.354, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1229, loss: 0.1229, grad_norm: 1.4870
2022-04-03 18:20:18,617 - depth - INFO - Epoch [5][500/1514]	lr: 6.703e-05, eta: 2:58:03, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1226, loss: 0.1226, grad_norm: 1.2528
2022-04-03 18:20:36,385 - depth - INFO - Epoch [5][550/1514]	lr: 6.769e-05, eta: 2:57:45, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1221, loss: 0.1221, grad_norm: 1.2398
2022-04-03 18:20:54,129 - depth - INFO - Epoch [5][600/1514]	lr: 6.834e-05, eta: 2:57:26, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1215, loss: 0.1215, grad_norm: 1.2179
2022-04-03 18:21:11,887 - depth - INFO - Epoch [5][650/1514]	lr: 6.899e-05, eta: 2:57:07, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1203, loss: 0.1203, grad_norm: 1.0553
2022-04-03 18:21:29,606 - depth - INFO - Epoch [5][700/1514]	lr: 6.963e-05, eta: 2:56:48, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1203, loss: 0.1203, grad_norm: 1.2071
2022-04-03 18:21:47,369 - depth - INFO - Epoch [5][750/1514]	lr: 7.027e-05, eta: 2:56:30, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1142, loss: 0.1142, grad_norm: 1.1353
2022-04-03 18:22:05,090 - depth - INFO - Epoch [5][800/1514]	lr: 7.091e-05, eta: 2:56:11, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1175, loss: 0.1175, grad_norm: 1.1026
2022-04-03 18:22:22,797 - depth - INFO - Epoch [5][850/1514]	lr: 7.155e-05, eta: 2:55:52, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1167, loss: 0.1167, grad_norm: 1.0749
2022-04-03 18:22:40,519 - depth - INFO - Epoch [5][900/1514]	lr: 7.218e-05, eta: 2:55:33, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1159, loss: 0.1159, grad_norm: 1.2306
2022-04-03 18:22:58,250 - depth - INFO - Epoch [5][950/1514]	lr: 7.280e-05, eta: 2:55:14, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1184, loss: 0.1184, grad_norm: 1.0983
2022-04-03 18:23:15,943 - depth - INFO - Epoch [5][1000/1514]	lr: 7.342e-05, eta: 2:54:56, time: 0.354, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1181, loss: 0.1181, grad_norm: 1.1433
2022-04-03 18:23:33,650 - depth - INFO - Epoch [5][1050/1514]	lr: 7.404e-05, eta: 2:54:37, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1181, loss: 0.1181, grad_norm: 1.1340
2022-04-03 18:23:51,392 - depth - INFO - Epoch [5][1100/1514]	lr: 7.465e-05, eta: 2:54:18, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1182, loss: 0.1182, grad_norm: 1.2318
2022-04-03 18:24:09,079 - depth - INFO - Epoch [5][1150/1514]	lr: 7.526e-05, eta: 2:53:59, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1214, loss: 0.1214, grad_norm: 1.2479
2022-04-03 18:24:26,784 - depth - INFO - Epoch [5][1200/1514]	lr: 7.586e-05, eta: 2:53:40, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1172, loss: 0.1172, grad_norm: 1.1864
2022-04-03 18:24:44,487 - depth - INFO - Epoch [5][1250/1514]	lr: 7.646e-05, eta: 2:53:22, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1181, loss: 0.1181, grad_norm: 1.4552
2022-04-03 18:25:02,230 - depth - INFO - Epoch [5][1300/1514]	lr: 7.705e-05, eta: 2:53:03, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1168, loss: 0.1168, grad_norm: 1.2283
2022-04-03 18:25:19,964 - depth - INFO - Epoch [5][1350/1514]	lr: 7.764e-05, eta: 2:52:44, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1196, loss: 0.1196, grad_norm: 1.3548
2022-04-03 18:25:37,684 - depth - INFO - Epoch [5][1400/1514]	lr: 7.822e-05, eta: 2:52:26, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1177, loss: 0.1177, grad_norm: 1.1209
2022-04-03 18:25:55,383 - depth - INFO - Epoch [5][1450/1514]	lr: 7.880e-05, eta: 2:52:07, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1149, loss: 0.1149, grad_norm: 1.2356
2022-04-03 18:26:13,081 - depth - INFO - Epoch [5][1500/1514]	lr: 7.937e-05, eta: 2:51:48, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1201, loss: 0.1201, grad_norm: 1.4009
2022-04-03 18:26:18,136 - depth - INFO - Saving checkpoint at 5 epochs
2022-04-03 18:26:38,559 - depth - INFO - Epoch [6][50/1514]	lr: 8.009e-05, eta: 2:51:14, time: 0.397, data_time: 0.050, memory: 15394, decode.loss_depth: 0.1148, loss: 0.1148, grad_norm: 1.2862
2022-04-03 18:26:56,259 - depth - INFO - Epoch [6][100/1514]	lr: 8.065e-05, eta: 2:50:55, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1110, loss: 0.1110, grad_norm: 1.0616
2022-04-03 18:27:13,958 - depth - INFO - Epoch [6][150/1514]	lr: 8.120e-05, eta: 2:50:37, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1166, loss: 0.1166, grad_norm: 1.1597
2022-04-03 18:27:31,702 - depth - INFO - Epoch [6][200/1514]	lr: 8.175e-05, eta: 2:50:18, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1184, loss: 0.1184, grad_norm: 1.3102
2022-04-03 18:27:49,398 - depth - INFO - Epoch [6][250/1514]	lr: 8.229e-05, eta: 2:50:00, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1118, loss: 0.1118, grad_norm: 1.1234
2022-04-03 18:28:07,106 - depth - INFO - Epoch [6][300/1514]	lr: 8.282e-05, eta: 2:49:41, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1147, loss: 0.1147, grad_norm: 1.1170
2022-04-03 18:28:24,819 - depth - INFO - Epoch [6][350/1514]	lr: 8.335e-05, eta: 2:49:23, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1148, loss: 0.1148, grad_norm: 1.1846
2022-04-03 18:28:42,509 - depth - INFO - Epoch [6][400/1514]	lr: 8.387e-05, eta: 2:49:04, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1097, loss: 0.1097, grad_norm: 1.0962
2022-04-03 18:29:00,137 - depth - INFO - Epoch [6][450/1514]	lr: 8.438e-05, eta: 2:48:45, time: 0.353, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1151, loss: 0.1151, grad_norm: 1.3002
2022-04-03 18:29:17,820 - depth - INFO - Epoch [6][500/1514]	lr: 8.489e-05, eta: 2:48:27, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1146, loss: 0.1146, grad_norm: 1.2304
2022-04-03 18:29:35,530 - depth - INFO - Epoch [6][550/1514]	lr: 8.539e-05, eta: 2:48:08, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1148, loss: 0.1148, grad_norm: 1.2916
2022-04-03 18:29:53,250 - depth - INFO - Epoch [6][600/1514]	lr: 8.588e-05, eta: 2:47:50, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1115, loss: 0.1115, grad_norm: 1.0734
2022-04-03 18:30:10,955 - depth - INFO - Epoch [6][650/1514]	lr: 8.637e-05, eta: 2:47:31, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1127, loss: 0.1127, grad_norm: 1.1584
2022-04-03 18:30:28,614 - depth - INFO - Epoch [6][700/1514]	lr: 8.685e-05, eta: 2:47:13, time: 0.353, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1120, loss: 0.1120, grad_norm: 1.2348
2022-04-03 18:30:46,355 - depth - INFO - Epoch [6][750/1514]	lr: 8.732e-05, eta: 2:46:54, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1098, loss: 0.1098, grad_norm: 1.1119
2022-04-03 18:31:04,023 - depth - INFO - Epoch [6][800/1514]	lr: 8.779e-05, eta: 2:46:36, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1085, loss: 0.1085, grad_norm: 1.0641
2022-04-03 18:31:21,680 - depth - INFO - Epoch [6][850/1514]	lr: 8.824e-05, eta: 2:46:17, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1065, loss: 0.1065, grad_norm: 1.1415
2022-04-03 18:31:39,344 - depth - INFO - Epoch [6][900/1514]	lr: 8.869e-05, eta: 2:45:59, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1081, loss: 0.1081, grad_norm: 1.1333
2022-04-03 18:31:57,042 - depth - INFO - Epoch [6][950/1514]	lr: 8.914e-05, eta: 2:45:40, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1078, loss: 0.1078, grad_norm: 1.0272
2022-04-03 18:32:14,719 - depth - INFO - Epoch [6][1000/1514]	lr: 8.957e-05, eta: 2:45:22, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1111, loss: 0.1111, grad_norm: 1.1245
2022-04-03 18:32:32,393 - depth - INFO - Epoch [6][1050/1514]	lr: 9.000e-05, eta: 2:45:03, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1091, loss: 0.1091, grad_norm: 1.0275
2022-04-03 18:32:50,077 - depth - INFO - Epoch [6][1100/1514]	lr: 9.042e-05, eta: 2:44:45, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1096, loss: 0.1096, grad_norm: 1.1388
2022-04-03 18:33:07,764 - depth - INFO - Epoch [6][1150/1514]	lr: 9.083e-05, eta: 2:44:26, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1094, loss: 0.1094, grad_norm: 1.1647
2022-04-03 18:33:25,443 - depth - INFO - Epoch [6][1200/1514]	lr: 9.123e-05, eta: 2:44:08, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1088, loss: 0.1088, grad_norm: 1.1861
2022-04-03 18:33:43,135 - depth - INFO - Epoch [6][1250/1514]	lr: 9.162e-05, eta: 2:43:50, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1109, loss: 0.1109, grad_norm: 1.2008
2022-04-03 18:34:00,814 - depth - INFO - Epoch [6][1300/1514]	lr: 9.201e-05, eta: 2:43:31, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1062, loss: 0.1062, grad_norm: 1.0424
2022-04-03 18:34:18,486 - depth - INFO - Epoch [6][1350/1514]	lr: 9.239e-05, eta: 2:43:13, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1086, loss: 0.1086, grad_norm: 1.2683
2022-04-03 18:34:36,192 - depth - INFO - Epoch [6][1400/1514]	lr: 9.276e-05, eta: 2:42:54, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1079, loss: 0.1079, grad_norm: 1.1002
2022-04-03 18:34:53,857 - depth - INFO - Epoch [6][1450/1514]	lr: 9.312e-05, eta: 2:42:36, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1075, loss: 0.1075, grad_norm: 1.1643
2022-04-03 18:35:11,554 - depth - INFO - Epoch [6][1500/1514]	lr: 9.347e-05, eta: 2:42:18, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1059, loss: 0.1059, grad_norm: 1.0560
2022-04-03 18:35:16,609 - depth - INFO - Saving checkpoint at 6 epochs
2022-04-03 18:35:57,632 - depth - INFO - Summary:
2022-04-03 18:35:57,632 - depth - INFO - 
+--------+--------+--------+---------+--------+--------+----------+---------+--------+
|   a1   |   a2   |   a3   | abs_rel |  rmse  | log_10 | rmse_log |  silog  | sq_rel |
+--------+--------+--------+---------+--------+--------+----------+---------+--------+
| 0.8272 | 0.9699 | 0.9933 |  0.1389 | 0.4512 | 0.0569 |  0.1673  | 13.6686 | 0.0881 |
+--------+--------+--------+---------+--------+--------+----------+---------+--------+
2022-04-03 18:35:57,633 - depth - INFO - Exp name: bts_r50_nyu_24e.py
2022-04-03 18:35:57,633 - depth - INFO - Epoch(val) [6][327]	a1: 0.8272, a2: 0.9699, a3: 0.9933, abs_rel: 0.13890768587589264, rmse: 0.4512045383453369, log_10: 0.05685975402593613, rmse_log: 0.16727891564369202, silog: 13.6686, sq_rel: 0.0880713015794754
2022-04-03 18:36:17,999 - depth - INFO - Epoch [7][50/1514]	lr: 9.391e-05, eta: 2:41:47, time: 0.407, data_time: 0.059, memory: 15394, decode.loss_depth: 0.1074, loss: 0.1074, grad_norm: 1.1553
2022-04-03 18:36:35,684 - depth - INFO - Epoch [7][100/1514]	lr: 9.424e-05, eta: 2:41:29, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1048, loss: 0.1048, grad_norm: 0.9640
2022-04-03 18:36:53,429 - depth - INFO - Epoch [7][150/1514]	lr: 9.457e-05, eta: 2:41:11, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1090, loss: 0.1090, grad_norm: 1.2009
2022-04-03 18:37:11,213 - depth - INFO - Epoch [7][200/1514]	lr: 9.488e-05, eta: 2:40:53, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1132, loss: 0.1132, grad_norm: 1.4330
2022-04-03 18:37:28,941 - depth - INFO - Epoch [7][250/1514]	lr: 9.519e-05, eta: 2:40:35, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1053, loss: 0.1053, grad_norm: 1.0164
2022-04-03 18:37:46,680 - depth - INFO - Epoch [7][300/1514]	lr: 9.549e-05, eta: 2:40:16, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1002, loss: 0.1002, grad_norm: 0.9577
2022-04-03 18:38:04,367 - depth - INFO - Epoch [7][350/1514]	lr: 9.577e-05, eta: 2:39:58, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1023, loss: 0.1023, grad_norm: 0.9706
2022-04-03 18:38:22,044 - depth - INFO - Epoch [7][400/1514]	lr: 9.605e-05, eta: 2:39:40, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1014, loss: 0.1014, grad_norm: 0.9272
2022-04-03 18:38:39,689 - depth - INFO - Epoch [7][450/1514]	lr: 9.632e-05, eta: 2:39:21, time: 0.353, data_time: 0.007, memory: 15394, decode.loss_depth: 0.1038, loss: 0.1038, grad_norm: 1.0930
2022-04-03 18:38:57,372 - depth - INFO - Epoch [7][500/1514]	lr: 9.658e-05, eta: 2:39:03, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1030, loss: 0.1030, grad_norm: 0.8687
2022-04-03 18:39:15,060 - depth - INFO - Epoch [7][550/1514]	lr: 9.684e-05, eta: 2:38:45, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1051, loss: 0.1051, grad_norm: 1.0057
2022-04-03 18:39:32,751 - depth - INFO - Epoch [7][600/1514]	lr: 9.708e-05, eta: 2:38:27, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1007, loss: 0.1007, grad_norm: 0.8904
2022-04-03 18:39:50,461 - depth - INFO - Epoch [7][650/1514]	lr: 9.731e-05, eta: 2:38:09, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1023, loss: 0.1023, grad_norm: 0.8584
2022-04-03 18:40:08,126 - depth - INFO - Epoch [7][700/1514]	lr: 9.753e-05, eta: 2:37:50, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1032, loss: 0.1032, grad_norm: 1.0006
2022-04-03 18:40:25,844 - depth - INFO - Epoch [7][750/1514]	lr: 9.775e-05, eta: 2:37:32, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1019, loss: 0.1019, grad_norm: 1.1480
2022-04-03 18:40:43,496 - depth - INFO - Epoch [7][800/1514]	lr: 9.795e-05, eta: 2:37:14, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1021, loss: 0.1021, grad_norm: 0.8673
2022-04-03 18:41:01,197 - depth - INFO - Epoch [7][850/1514]	lr: 9.815e-05, eta: 2:36:56, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0992, loss: 0.0992, grad_norm: 0.9808
2022-04-03 18:41:18,904 - depth - INFO - Epoch [7][900/1514]	lr: 9.833e-05, eta: 2:36:37, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0988, loss: 0.0988, grad_norm: 1.0413
2022-04-03 18:41:36,633 - depth - INFO - Epoch [7][950/1514]	lr: 9.851e-05, eta: 2:36:19, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1006, loss: 0.1006, grad_norm: 1.0566
2022-04-03 18:41:54,319 - depth - INFO - Epoch [7][1000/1514]	lr: 9.868e-05, eta: 2:36:01, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0992, loss: 0.0992, grad_norm: 0.8954
2022-04-03 18:42:12,027 - depth - INFO - Epoch [7][1050/1514]	lr: 9.883e-05, eta: 2:35:43, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0973, loss: 0.0973, grad_norm: 0.8419
2022-04-03 18:42:29,773 - depth - INFO - Epoch [7][1100/1514]	lr: 9.898e-05, eta: 2:35:25, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1005, loss: 0.1005, grad_norm: 0.9058
2022-04-03 18:42:47,525 - depth - INFO - Epoch [7][1150/1514]	lr: 9.912e-05, eta: 2:35:07, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1006, loss: 0.1006, grad_norm: 0.9335
2022-04-03 18:43:05,278 - depth - INFO - Epoch [7][1200/1514]	lr: 9.924e-05, eta: 2:34:49, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0961, loss: 0.0961, grad_norm: 1.0246
2022-04-03 18:43:23,014 - depth - INFO - Epoch [7][1250/1514]	lr: 9.936e-05, eta: 2:34:31, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0996, loss: 0.0996, grad_norm: 1.1118
2022-04-03 18:43:40,730 - depth - INFO - Epoch [7][1300/1514]	lr: 9.947e-05, eta: 2:34:13, time: 0.354, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0975, loss: 0.0975, grad_norm: 0.9451
2022-04-03 18:43:58,470 - depth - INFO - Epoch [7][1350/1514]	lr: 9.957e-05, eta: 2:33:55, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.1012, loss: 0.1012, grad_norm: 1.3378
2022-04-03 18:44:16,198 - depth - INFO - Epoch [7][1400/1514]	lr: 9.965e-05, eta: 2:33:37, time: 0.355, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0989, loss: 0.0989, grad_norm: 1.1244
2022-04-03 18:44:33,935 - depth - INFO - Epoch [7][1450/1514]	lr: 9.973e-05, eta: 2:33:19, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0998, loss: 0.0998, grad_norm: 1.0640
2022-04-03 18:44:51,667 - depth - INFO - Epoch [7][1500/1514]	lr: 9.980e-05, eta: 2:33:01, time: 0.355, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0964, loss: 0.0964, grad_norm: 0.9679
2022-04-03 18:44:56,740 - depth - INFO - Saving checkpoint at 7 epochs
2022-04-03 18:45:17,110 - depth - INFO - Epoch [8][50/1514]	lr: 9.987e-05, eta: 2:32:30, time: 0.395, data_time: 0.049, memory: 15394, decode.loss_depth: 0.0975, loss: 0.0975, grad_norm: 1.0501
2022-04-03 18:45:34,725 - depth - INFO - Epoch [8][100/1514]	lr: 9.992e-05, eta: 2:32:12, time: 0.352, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0976, loss: 0.0976, grad_norm: 0.7968
2022-04-03 18:45:52,395 - depth - INFO - Epoch [8][150/1514]	lr: 9.995e-05, eta: 2:31:54, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0993, loss: 0.0993, grad_norm: 1.0275
2022-04-03 18:46:10,075 - depth - INFO - Epoch [8][200/1514]	lr: 9.998e-05, eta: 2:31:36, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.1001, loss: 0.1001, grad_norm: 1.1517
2022-04-03 18:46:27,758 - depth - INFO - Epoch [8][250/1514]	lr: 9.999e-05, eta: 2:31:18, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0934, loss: 0.0934, grad_norm: 0.8009
2022-04-03 18:46:45,443 - depth - INFO - Epoch [8][300/1514]	lr: 1.000e-04, eta: 2:31:00, time: 0.354, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0938, loss: 0.0938, grad_norm: 0.8953
2022-04-03 18:47:03,049 - depth - INFO - Epoch [8][350/1514]	lr: 1.000e-04, eta: 2:30:41, time: 0.352, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0937, loss: 0.0937, grad_norm: 0.9097
2022-04-03 18:47:20,718 - depth - INFO - Epoch [8][400/1514]	lr: 1.000e-04, eta: 2:30:23, time: 0.353, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0928, loss: 0.0928, grad_norm: 0.9175
2022-04-03 18:47:38,333 - depth - INFO - Epoch [8][450/1514]	lr: 9.999e-05, eta: 2:30:05, time: 0.352, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0951, loss: 0.0951, grad_norm: 1.0589
2022-04-03 18:47:56,032 - depth - INFO - Epoch [8][500/1514]	lr: 9.999e-05, eta: 2:29:47, time: 0.354, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0972, loss: 0.0972, grad_norm: 1.0535
2022-04-03 18:48:13,914 - depth - INFO - Epoch [8][550/1514]	lr: 9.998e-05, eta: 2:29:29, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0965, loss: 0.0965, grad_norm: 1.0445
2022-04-03 18:48:32,076 - depth - INFO - Epoch [8][600/1514]	lr: 9.997e-05, eta: 2:29:12, time: 0.363, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0929, loss: 0.0929, grad_norm: 0.7261
2022-04-03 18:48:55,623 - depth - INFO - Epoch [8][650/1514]	lr: 9.995e-05, eta: 2:29:07, time: 0.471, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0962, loss: 0.0962, grad_norm: 0.9415
2022-04-03 18:49:22,055 - depth - INFO - Epoch [8][700/1514]	lr: 9.994e-05, eta: 2:29:08, time: 0.529, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0958, loss: 0.0958, grad_norm: 1.1343
2022-04-03 18:49:45,944 - depth - INFO - Epoch [8][750/1514]	lr: 9.992e-05, eta: 2:29:04, time: 0.478, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0927, loss: 0.0927, grad_norm: 0.9664
2022-04-03 18:50:03,724 - depth - INFO - Epoch [8][800/1514]	lr: 9.991e-05, eta: 2:28:46, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0925, loss: 0.0925, grad_norm: 0.8710
2022-04-03 18:50:21,608 - depth - INFO - Epoch [8][850/1514]	lr: 9.989e-05, eta: 2:28:28, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0925, loss: 0.0925, grad_norm: 0.8944
2022-04-03 18:50:39,452 - depth - INFO - Epoch [8][900/1514]	lr: 9.986e-05, eta: 2:28:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0892, loss: 0.0892, grad_norm: 0.8328
2022-04-03 18:50:57,791 - depth - INFO - Epoch [8][950/1514]	lr: 9.984e-05, eta: 2:27:53, time: 0.367, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0894, loss: 0.0894, grad_norm: 0.7491
2022-04-03 18:51:19,799 - depth - INFO - Epoch [8][1000/1514]	lr: 9.981e-05, eta: 2:27:44, time: 0.440, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0915, loss: 0.0915, grad_norm: 0.9408
2022-04-03 18:51:44,498 - depth - INFO - Epoch [8][1050/1514]	lr: 9.979e-05, eta: 2:27:40, time: 0.494, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0919, loss: 0.0919, grad_norm: 0.8922
2022-04-03 18:52:02,345 - depth - INFO - Epoch [8][1100/1514]	lr: 9.976e-05, eta: 2:27:22, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0919, loss: 0.0919, grad_norm: 0.9512
2022-04-03 18:52:20,222 - depth - INFO - Epoch [8][1150/1514]	lr: 9.973e-05, eta: 2:27:04, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0935, loss: 0.0935, grad_norm: 0.9269
2022-04-03 18:52:38,067 - depth - INFO - Epoch [8][1200/1514]	lr: 9.969e-05, eta: 2:26:46, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0918, loss: 0.0918, grad_norm: 0.9454
2022-04-03 18:52:55,916 - depth - INFO - Epoch [8][1250/1514]	lr: 9.966e-05, eta: 2:26:28, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0934, loss: 0.0934, grad_norm: 1.0681
2022-04-03 18:53:14,224 - depth - INFO - Epoch [8][1300/1514]	lr: 9.962e-05, eta: 2:26:10, time: 0.366, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0916, loss: 0.0916, grad_norm: 0.8845
2022-04-03 18:53:33,955 - depth - INFO - Epoch [8][1350/1514]	lr: 9.958e-05, eta: 2:25:56, time: 0.394, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0895, loss: 0.0895, grad_norm: 0.7719
2022-04-03 18:54:04,199 - depth - INFO - Epoch [8][1400/1514]	lr: 9.954e-05, eta: 2:26:03, time: 0.605, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0892, loss: 0.0892, grad_norm: 0.6684
2022-04-03 18:54:34,739 - depth - INFO - Epoch [8][1450/1514]	lr: 9.950e-05, eta: 2:26:10, time: 0.611, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0870, loss: 0.0870, grad_norm: 0.8993
2022-04-03 18:54:53,043 - depth - INFO - Epoch [8][1500/1514]	lr: 9.945e-05, eta: 2:25:53, time: 0.366, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0867, loss: 0.0867, grad_norm: 0.8005
2022-04-03 18:54:58,140 - depth - INFO - Saving checkpoint at 8 epochs
2022-04-03 18:55:18,720 - depth - INFO - Epoch [9][50/1514]	lr: 9.939e-05, eta: 2:25:23, time: 0.399, data_time: 0.051, memory: 15394, decode.loss_depth: 0.0857, loss: 0.0857, grad_norm: 0.7449
2022-04-03 18:55:36,527 - depth - INFO - Epoch [9][100/1514]	lr: 9.935e-05, eta: 2:25:05, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0858, loss: 0.0858, grad_norm: 0.7832
2022-04-03 18:55:54,397 - depth - INFO - Epoch [9][150/1514]	lr: 9.930e-05, eta: 2:24:46, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0886, loss: 0.0886, grad_norm: 0.9195
2022-04-03 18:56:12,277 - depth - INFO - Epoch [9][200/1514]	lr: 9.924e-05, eta: 2:24:28, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0918, loss: 0.0918, grad_norm: 1.1270
2022-04-03 18:56:30,136 - depth - INFO - Epoch [9][250/1514]	lr: 9.919e-05, eta: 2:24:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0877, loss: 0.0877, grad_norm: 0.8089
2022-04-03 18:56:48,020 - depth - INFO - Epoch [9][300/1514]	lr: 9.913e-05, eta: 2:23:51, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0880, loss: 0.0880, grad_norm: 0.9344
2022-04-03 18:57:05,866 - depth - INFO - Epoch [9][350/1514]	lr: 9.907e-05, eta: 2:23:33, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0866, loss: 0.0866, grad_norm: 0.7575
2022-04-03 18:57:23,672 - depth - INFO - Epoch [9][400/1514]	lr: 9.901e-05, eta: 2:23:14, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0835, loss: 0.0835, grad_norm: 0.8279
2022-04-03 18:57:41,438 - depth - INFO - Epoch [9][450/1514]	lr: 9.895e-05, eta: 2:22:56, time: 0.355, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0841, loss: 0.0841, grad_norm: 0.8002
2022-04-03 18:57:59,276 - depth - INFO - Epoch [9][500/1514]	lr: 9.889e-05, eta: 2:22:38, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0869, loss: 0.0869, grad_norm: 0.9540
2022-04-03 18:58:17,113 - depth - INFO - Epoch [9][550/1514]	lr: 9.882e-05, eta: 2:22:19, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0873, loss: 0.0873, grad_norm: 0.9661
2022-04-03 18:58:35,014 - depth - INFO - Epoch [9][600/1514]	lr: 9.875e-05, eta: 2:22:01, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0837, loss: 0.0837, grad_norm: 0.7478
2022-04-03 18:58:52,920 - depth - INFO - Epoch [9][650/1514]	lr: 9.869e-05, eta: 2:21:43, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0854, loss: 0.0854, grad_norm: 0.6511
2022-04-03 18:59:10,782 - depth - INFO - Epoch [9][700/1514]	lr: 9.861e-05, eta: 2:21:24, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0868, loss: 0.0868, grad_norm: 0.9646
2022-04-03 18:59:28,673 - depth - INFO - Epoch [9][750/1514]	lr: 9.854e-05, eta: 2:21:06, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0824, loss: 0.0824, grad_norm: 0.8155
2022-04-03 18:59:46,526 - depth - INFO - Epoch [9][800/1514]	lr: 9.847e-05, eta: 2:20:48, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0840, loss: 0.0840, grad_norm: 0.8021
2022-04-03 19:00:04,351 - depth - INFO - Epoch [9][850/1514]	lr: 9.839e-05, eta: 2:20:29, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0827, loss: 0.0827, grad_norm: 0.6960
2022-04-03 19:00:22,221 - depth - INFO - Epoch [9][900/1514]	lr: 9.831e-05, eta: 2:20:11, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0831, loss: 0.0831, grad_norm: 0.9206
2022-04-03 19:00:40,106 - depth - INFO - Epoch [9][950/1514]	lr: 9.823e-05, eta: 2:19:53, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0855, loss: 0.0855, grad_norm: 1.0940
2022-04-03 19:00:57,895 - depth - INFO - Epoch [9][1000/1514]	lr: 9.815e-05, eta: 2:19:34, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0833, loss: 0.0833, grad_norm: 1.0850
2022-04-03 19:01:15,755 - depth - INFO - Epoch [9][1050/1514]	lr: 9.806e-05, eta: 2:19:16, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0822, loss: 0.0822, grad_norm: 0.9348
2022-04-03 19:01:33,634 - depth - INFO - Epoch [9][1100/1514]	lr: 9.798e-05, eta: 2:18:57, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0831, loss: 0.0831, grad_norm: 0.9620
2022-04-03 19:01:51,526 - depth - INFO - Epoch [9][1150/1514]	lr: 9.789e-05, eta: 2:18:39, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0853, loss: 0.0853, grad_norm: 0.9239
2022-04-03 19:02:09,394 - depth - INFO - Epoch [9][1200/1514]	lr: 9.780e-05, eta: 2:18:21, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0829, loss: 0.0829, grad_norm: 0.6816
2022-04-03 19:02:27,250 - depth - INFO - Epoch [9][1250/1514]	lr: 9.771e-05, eta: 2:18:03, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0833, loss: 0.0833, grad_norm: 0.8495
2022-04-03 19:02:45,115 - depth - INFO - Epoch [9][1300/1514]	lr: 9.762e-05, eta: 2:17:44, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0833, loss: 0.0833, grad_norm: 0.7962
2022-04-03 19:03:03,002 - depth - INFO - Epoch [9][1350/1514]	lr: 9.752e-05, eta: 2:17:26, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0817, loss: 0.0817, grad_norm: 0.8101
2022-04-03 19:03:20,893 - depth - INFO - Epoch [9][1400/1514]	lr: 9.742e-05, eta: 2:17:08, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0800, loss: 0.0800, grad_norm: 0.7221
2022-04-03 19:03:38,749 - depth - INFO - Epoch [9][1450/1514]	lr: 9.732e-05, eta: 2:16:49, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0800, loss: 0.0800, grad_norm: 0.7933
2022-04-03 19:03:56,595 - depth - INFO - Epoch [9][1500/1514]	lr: 9.722e-05, eta: 2:16:31, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0839, loss: 0.0839, grad_norm: 1.0670
2022-04-03 19:04:01,702 - depth - INFO - Saving checkpoint at 9 epochs
2022-04-03 19:04:22,226 - depth - INFO - Epoch [10][50/1514]	lr: 9.709e-05, eta: 2:16:03, time: 0.398, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0868, loss: 0.0868, grad_norm: 0.8644
2022-04-03 19:04:40,083 - depth - INFO - Epoch [10][100/1514]	lr: 9.699e-05, eta: 2:15:45, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0825, loss: 0.0825, grad_norm: 0.7773
2022-04-03 19:04:57,947 - depth - INFO - Epoch [10][150/1514]	lr: 9.688e-05, eta: 2:15:26, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0837, loss: 0.0837, grad_norm: 1.0396
2022-04-03 19:05:15,817 - depth - INFO - Epoch [10][200/1514]	lr: 9.677e-05, eta: 2:15:08, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0829, loss: 0.0829, grad_norm: 0.8938
2022-04-03 19:05:33,668 - depth - INFO - Epoch [10][250/1514]	lr: 9.666e-05, eta: 2:14:50, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0808, loss: 0.0808, grad_norm: 0.8221
2022-04-03 19:05:51,554 - depth - INFO - Epoch [10][300/1514]	lr: 9.655e-05, eta: 2:14:32, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0798, loss: 0.0798, grad_norm: 0.7226
2022-04-03 19:06:09,385 - depth - INFO - Epoch [10][350/1514]	lr: 9.644e-05, eta: 2:14:13, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0764, loss: 0.0764, grad_norm: 0.5949
2022-04-03 19:06:27,188 - depth - INFO - Epoch [10][400/1514]	lr: 9.632e-05, eta: 2:13:55, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0765, loss: 0.0765, grad_norm: 0.6229
2022-04-03 19:06:44,977 - depth - INFO - Epoch [10][450/1514]	lr: 9.621e-05, eta: 2:13:37, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0779, loss: 0.0779, grad_norm: 0.6798
2022-04-03 19:07:02,828 - depth - INFO - Epoch [10][500/1514]	lr: 9.609e-05, eta: 2:13:18, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0782, loss: 0.0782, grad_norm: 0.6349
2022-04-03 19:07:20,675 - depth - INFO - Epoch [10][550/1514]	lr: 9.597e-05, eta: 2:13:00, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0803, loss: 0.0803, grad_norm: 0.7695
2022-04-03 19:07:38,545 - depth - INFO - Epoch [10][600/1514]	lr: 9.584e-05, eta: 2:12:42, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0767, loss: 0.0767, grad_norm: 0.6525
2022-04-03 19:07:56,396 - depth - INFO - Epoch [10][650/1514]	lr: 9.572e-05, eta: 2:12:24, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0780, loss: 0.0780, grad_norm: 0.7293
2022-04-03 19:08:14,212 - depth - INFO - Epoch [10][700/1514]	lr: 9.559e-05, eta: 2:12:05, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0785, loss: 0.0785, grad_norm: 0.8794
2022-04-03 19:08:32,085 - depth - INFO - Epoch [10][750/1514]	lr: 9.547e-05, eta: 2:11:47, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0763, loss: 0.0763, grad_norm: 0.8594
2022-04-03 19:08:49,912 - depth - INFO - Epoch [10][800/1514]	lr: 9.534e-05, eta: 2:11:29, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0762, loss: 0.0762, grad_norm: 0.7418
2022-04-03 19:09:07,742 - depth - INFO - Epoch [10][850/1514]	lr: 9.521e-05, eta: 2:11:11, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0753, loss: 0.0753, grad_norm: 0.8434
2022-04-03 19:09:25,599 - depth - INFO - Epoch [10][900/1514]	lr: 9.507e-05, eta: 2:10:52, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0762, loss: 0.0762, grad_norm: 0.9136
2022-04-03 19:09:43,443 - depth - INFO - Epoch [10][950/1514]	lr: 9.494e-05, eta: 2:10:34, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0785, loss: 0.0785, grad_norm: 0.9725
2022-04-03 19:10:01,258 - depth - INFO - Epoch [10][1000/1514]	lr: 9.480e-05, eta: 2:10:16, time: 0.356, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0785, loss: 0.0785, grad_norm: 0.9295
2022-04-03 19:10:19,140 - depth - INFO - Epoch [10][1050/1514]	lr: 9.466e-05, eta: 2:09:58, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0774, loss: 0.0774, grad_norm: 0.9572
2022-04-03 19:10:37,011 - depth - INFO - Epoch [10][1100/1514]	lr: 9.452e-05, eta: 2:09:39, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0788, loss: 0.0788, grad_norm: 1.0130
2022-04-03 19:10:54,862 - depth - INFO - Epoch [10][1150/1514]	lr: 9.438e-05, eta: 2:09:21, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0794, loss: 0.0794, grad_norm: 0.7621
2022-04-03 19:11:12,737 - depth - INFO - Epoch [10][1200/1514]	lr: 9.424e-05, eta: 2:09:03, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0766, loss: 0.0766, grad_norm: 0.8296
2022-04-03 19:11:30,589 - depth - INFO - Epoch [10][1250/1514]	lr: 9.410e-05, eta: 2:08:45, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0824, loss: 0.0824, grad_norm: 1.4097
2022-04-03 19:11:48,464 - depth - INFO - Epoch [10][1300/1514]	lr: 9.395e-05, eta: 2:08:27, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0797, loss: 0.0797, grad_norm: 0.8874
2022-04-03 19:12:06,328 - depth - INFO - Epoch [10][1350/1514]	lr: 9.380e-05, eta: 2:08:08, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0763, loss: 0.0763, grad_norm: 0.7159
2022-04-03 19:12:24,243 - depth - INFO - Epoch [10][1400/1514]	lr: 9.365e-05, eta: 2:07:50, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0753, loss: 0.0753, grad_norm: 0.6838
2022-04-03 19:12:42,116 - depth - INFO - Epoch [10][1450/1514]	lr: 9.350e-05, eta: 2:07:32, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0740, loss: 0.0740, grad_norm: 0.7034
2022-04-03 19:12:59,999 - depth - INFO - Epoch [10][1500/1514]	lr: 9.335e-05, eta: 2:07:14, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0739, loss: 0.0739, grad_norm: 0.7694
2022-04-03 19:13:05,102 - depth - INFO - Saving checkpoint at 10 epochs
2022-04-03 19:13:25,693 - depth - INFO - Epoch [11][50/1514]	lr: 9.315e-05, eta: 2:06:47, time: 0.399, data_time: 0.051, memory: 15394, decode.loss_depth: 0.0736, loss: 0.0736, grad_norm: 0.6091
2022-04-03 19:13:43,522 - depth - INFO - Epoch [11][100/1514]	lr: 9.299e-05, eta: 2:06:28, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0754, loss: 0.0754, grad_norm: 0.6102
2022-04-03 19:14:01,364 - depth - INFO - Epoch [11][150/1514]	lr: 9.283e-05, eta: 2:06:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0750, loss: 0.0750, grad_norm: 0.8304
2022-04-03 19:14:19,234 - depth - INFO - Epoch [11][200/1514]	lr: 9.267e-05, eta: 2:05:52, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0769, loss: 0.0769, grad_norm: 0.9180
2022-04-03 19:14:37,104 - depth - INFO - Epoch [11][250/1514]	lr: 9.251e-05, eta: 2:05:34, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0739, loss: 0.0739, grad_norm: 0.7892
2022-04-03 19:14:54,982 - depth - INFO - Epoch [11][300/1514]	lr: 9.235e-05, eta: 2:05:16, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0726, loss: 0.0726, grad_norm: 0.8005
2022-04-03 19:15:12,840 - depth - INFO - Epoch [11][350/1514]	lr: 9.218e-05, eta: 2:04:58, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0741, loss: 0.0741, grad_norm: 0.9308
2022-04-03 19:15:30,683 - depth - INFO - Epoch [11][400/1514]	lr: 9.202e-05, eta: 2:04:39, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0715, loss: 0.0715, grad_norm: 0.6539
2022-04-03 19:15:48,476 - depth - INFO - Epoch [11][450/1514]	lr: 9.185e-05, eta: 2:04:21, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0731, loss: 0.0731, grad_norm: 0.6631
2022-04-03 19:16:06,311 - depth - INFO - Epoch [11][500/1514]	lr: 9.168e-05, eta: 2:04:03, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0743, loss: 0.0743, grad_norm: 0.8327
2022-04-03 19:16:24,192 - depth - INFO - Epoch [11][550/1514]	lr: 9.151e-05, eta: 2:03:45, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0799, loss: 0.0799, grad_norm: 1.2978
2022-04-03 19:16:42,068 - depth - INFO - Epoch [11][600/1514]	lr: 9.133e-05, eta: 2:03:27, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0782, loss: 0.0782, grad_norm: 1.0018
2022-04-03 19:16:59,948 - depth - INFO - Epoch [11][650/1514]	lr: 9.116e-05, eta: 2:03:09, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0747, loss: 0.0747, grad_norm: 0.6438
2022-04-03 19:17:17,759 - depth - INFO - Epoch [11][700/1514]	lr: 9.098e-05, eta: 2:02:50, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0736, loss: 0.0736, grad_norm: 0.8878
2022-04-03 19:17:35,627 - depth - INFO - Epoch [11][750/1514]	lr: 9.081e-05, eta: 2:02:32, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0749, loss: 0.0749, grad_norm: 1.2371
2022-04-03 19:17:53,471 - depth - INFO - Epoch [11][800/1514]	lr: 9.063e-05, eta: 2:02:14, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0721, loss: 0.0721, grad_norm: 0.7543
2022-04-03 19:18:11,318 - depth - INFO - Epoch [11][850/1514]	lr: 9.045e-05, eta: 2:01:56, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0704, loss: 0.0704, grad_norm: 0.8318
2022-04-03 19:18:29,178 - depth - INFO - Epoch [11][900/1514]	lr: 9.026e-05, eta: 2:01:38, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0706, loss: 0.0706, grad_norm: 0.6694
2022-04-03 19:18:47,047 - depth - INFO - Epoch [11][950/1514]	lr: 9.008e-05, eta: 2:01:20, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0719, loss: 0.0719, grad_norm: 0.7634
2022-04-03 19:19:04,897 - depth - INFO - Epoch [11][1000/1514]	lr: 8.990e-05, eta: 2:01:02, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0723, loss: 0.0723, grad_norm: 0.9983
2022-04-03 19:19:22,758 - depth - INFO - Epoch [11][1050/1514]	lr: 8.971e-05, eta: 2:00:44, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0721, loss: 0.0721, grad_norm: 0.8489
2022-04-03 19:19:40,615 - depth - INFO - Epoch [11][1100/1514]	lr: 8.952e-05, eta: 2:00:25, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0714, loss: 0.0714, grad_norm: 0.5574
2022-04-03 19:19:58,472 - depth - INFO - Epoch [11][1150/1514]	lr: 8.933e-05, eta: 2:00:07, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0729, loss: 0.0729, grad_norm: 0.6997
2022-04-03 19:20:16,323 - depth - INFO - Epoch [11][1200/1514]	lr: 8.914e-05, eta: 1:59:49, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0728, loss: 0.0728, grad_norm: 0.8886
2022-04-03 19:20:34,169 - depth - INFO - Epoch [11][1250/1514]	lr: 8.895e-05, eta: 1:59:31, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0732, loss: 0.0732, grad_norm: 1.2501
2022-04-03 19:20:52,035 - depth - INFO - Epoch [11][1300/1514]	lr: 8.875e-05, eta: 1:59:13, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0712, loss: 0.0712, grad_norm: 0.8052
2022-04-03 19:21:09,878 - depth - INFO - Epoch [11][1350/1514]	lr: 8.856e-05, eta: 1:58:55, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0692, loss: 0.0692, grad_norm: 0.6234
2022-04-03 19:21:27,749 - depth - INFO - Epoch [11][1400/1514]	lr: 8.836e-05, eta: 1:58:37, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0705, loss: 0.0705, grad_norm: 0.7254
2022-04-03 19:21:45,621 - depth - INFO - Epoch [11][1450/1514]	lr: 8.816e-05, eta: 1:58:19, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0681, loss: 0.0681, grad_norm: 0.5777
2022-04-03 19:22:03,486 - depth - INFO - Epoch [11][1500/1514]	lr: 8.796e-05, eta: 1:58:00, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0688, loss: 0.0688, grad_norm: 0.7430
2022-04-03 19:22:08,590 - depth - INFO - Saving checkpoint at 11 epochs
2022-04-03 19:22:29,169 - depth - INFO - Epoch [12][50/1514]	lr: 8.770e-05, eta: 1:57:34, time: 0.399, data_time: 0.049, memory: 15394, decode.loss_depth: 0.0693, loss: 0.0693, grad_norm: 0.7334
2022-04-03 19:22:47,048 - depth - INFO - Epoch [12][100/1514]	lr: 8.750e-05, eta: 1:57:16, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0691, loss: 0.0691, grad_norm: 0.7257
2022-04-03 19:23:04,951 - depth - INFO - Epoch [12][150/1514]	lr: 8.729e-05, eta: 1:56:58, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0718, loss: 0.0718, grad_norm: 0.8983
2022-04-03 19:23:22,860 - depth - INFO - Epoch [12][200/1514]	lr: 8.709e-05, eta: 1:56:40, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0738, loss: 0.0738, grad_norm: 1.0164
2022-04-03 19:23:40,713 - depth - INFO - Epoch [12][250/1514]	lr: 8.688e-05, eta: 1:56:22, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0718, loss: 0.0718, grad_norm: 1.1250
2022-04-03 19:23:58,599 - depth - INFO - Epoch [12][300/1514]	lr: 8.667e-05, eta: 1:56:04, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0683, loss: 0.0683, grad_norm: 0.7167
2022-04-03 19:24:16,466 - depth - INFO - Epoch [12][350/1514]	lr: 8.646e-05, eta: 1:55:45, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0679, loss: 0.0679, grad_norm: 0.8394
2022-04-03 19:24:34,312 - depth - INFO - Epoch [12][400/1514]	lr: 8.625e-05, eta: 1:55:27, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0683, loss: 0.0683, grad_norm: 1.0025
2022-04-03 19:24:52,164 - depth - INFO - Epoch [12][450/1514]	lr: 8.603e-05, eta: 1:55:09, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0686, loss: 0.0686, grad_norm: 0.7861
2022-04-03 19:25:10,058 - depth - INFO - Epoch [12][500/1514]	lr: 8.582e-05, eta: 1:54:51, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0685, loss: 0.0685, grad_norm: 0.7669
2022-04-03 19:25:27,913 - depth - INFO - Epoch [12][550/1514]	lr: 8.560e-05, eta: 1:54:33, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0726, loss: 0.0726, grad_norm: 1.0780
2022-04-03 19:25:45,788 - depth - INFO - Epoch [12][600/1514]	lr: 8.539e-05, eta: 1:54:15, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0687, loss: 0.0687, grad_norm: 0.7076
2022-04-03 19:26:03,644 - depth - INFO - Epoch [12][650/1514]	lr: 8.517e-05, eta: 1:53:57, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0687, loss: 0.0687, grad_norm: 0.6848
2022-04-03 19:26:21,426 - depth - INFO - Epoch [12][700/1514]	lr: 8.495e-05, eta: 1:53:39, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0680, loss: 0.0680, grad_norm: 0.6009
2022-04-03 19:26:39,309 - depth - INFO - Epoch [12][750/1514]	lr: 8.473e-05, eta: 1:53:21, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0656, loss: 0.0656, grad_norm: 0.6519
2022-04-03 19:26:57,170 - depth - INFO - Epoch [12][800/1514]	lr: 8.450e-05, eta: 1:53:03, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0655, loss: 0.0655, grad_norm: 0.7086
2022-04-03 19:27:15,040 - depth - INFO - Epoch [12][850/1514]	lr: 8.428e-05, eta: 1:52:45, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0653, loss: 0.0653, grad_norm: 0.7502
2022-04-03 19:27:32,889 - depth - INFO - Epoch [12][900/1514]	lr: 8.405e-05, eta: 1:52:27, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0659, loss: 0.0659, grad_norm: 0.7444
2022-04-03 19:27:50,783 - depth - INFO - Epoch [12][950/1514]	lr: 8.383e-05, eta: 1:52:09, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0661, loss: 0.0661, grad_norm: 0.6309
2022-04-03 19:28:08,644 - depth - INFO - Epoch [12][1000/1514]	lr: 8.360e-05, eta: 1:51:50, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0657, loss: 0.0657, grad_norm: 0.6412
2022-04-03 19:28:26,483 - depth - INFO - Epoch [12][1050/1514]	lr: 8.337e-05, eta: 1:51:32, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0642, loss: 0.0642, grad_norm: 0.7122
2022-04-03 19:28:44,343 - depth - INFO - Epoch [12][1100/1514]	lr: 8.314e-05, eta: 1:51:14, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0663, loss: 0.0663, grad_norm: 0.5578
2022-04-03 19:29:02,183 - depth - INFO - Epoch [12][1150/1514]	lr: 8.291e-05, eta: 1:50:56, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0663, loss: 0.0663, grad_norm: 0.5982
2022-04-03 19:29:20,063 - depth - INFO - Epoch [12][1200/1514]	lr: 8.267e-05, eta: 1:50:38, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0647, loss: 0.0647, grad_norm: 0.6977
2022-04-03 19:29:37,914 - depth - INFO - Epoch [12][1250/1514]	lr: 8.244e-05, eta: 1:50:20, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0663, loss: 0.0663, grad_norm: 0.9198
2022-04-03 19:29:55,785 - depth - INFO - Epoch [12][1300/1514]	lr: 8.220e-05, eta: 1:50:02, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0653, loss: 0.0653, grad_norm: 0.6399
2022-04-03 19:30:13,645 - depth - INFO - Epoch [12][1350/1514]	lr: 8.197e-05, eta: 1:49:44, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0646, loss: 0.0646, grad_norm: 0.5883
2022-04-03 19:30:31,529 - depth - INFO - Epoch [12][1400/1514]	lr: 8.173e-05, eta: 1:49:26, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0647, loss: 0.0647, grad_norm: 0.5805
2022-04-03 19:30:49,412 - depth - INFO - Epoch [12][1450/1514]	lr: 8.149e-05, eta: 1:49:08, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0633, loss: 0.0633, grad_norm: 0.6036
2022-04-03 19:31:07,278 - depth - INFO - Epoch [12][1500/1514]	lr: 8.125e-05, eta: 1:48:50, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0641, loss: 0.0641, grad_norm: 0.7850
2022-04-03 19:31:12,383 - depth - INFO - Saving checkpoint at 12 epochs
2022-04-03 19:31:31,884 - depth - INFO - Summary:
2022-04-03 19:31:31,884 - depth - INFO - 
+------+--------+-------+---------+--------+--------+----------+---------+--------+
|  a1  |   a2   |   a3  | abs_rel |  rmse  | log_10 | rmse_log |  silog  | sq_rel |
+------+--------+-------+---------+--------+--------+----------+---------+--------+
| 0.85 | 0.9748 | 0.994 |  0.1286 | 0.4211 | 0.0527 |  0.1559  | 12.4375 | 0.0775 |
+------+--------+-------+---------+--------+--------+----------+---------+--------+
2022-04-03 19:31:31,884 - depth - INFO - Exp name: bts_r50_nyu_24e.py
2022-04-03 19:31:31,884 - depth - INFO - Epoch(val) [12][327]	a1: 0.8500, a2: 0.9748, a3: 0.9940, abs_rel: 0.12862592935562134, rmse: 0.4210658669471741, log_10: 0.05273992940783501, rmse_log: 0.1559477150440216, silog: 12.4375, sq_rel: 0.07745419442653656
2022-04-03 19:31:52,430 - depth - INFO - Epoch [13][50/1514]	lr: 8.094e-05, eta: 1:48:24, time: 0.411, data_time: 0.058, memory: 15394, decode.loss_depth: 0.0632, loss: 0.0632, grad_norm: 0.6943
2022-04-03 19:32:10,281 - depth - INFO - Epoch [13][100/1514]	lr: 8.070e-05, eta: 1:48:06, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0658, loss: 0.0658, grad_norm: 0.6769
2022-04-03 19:32:28,182 - depth - INFO - Epoch [13][150/1514]	lr: 8.045e-05, eta: 1:47:48, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0654, loss: 0.0654, grad_norm: 0.6173
2022-04-03 19:32:46,090 - depth - INFO - Epoch [13][200/1514]	lr: 8.021e-05, eta: 1:47:30, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0680, loss: 0.0680, grad_norm: 1.0488
2022-04-03 19:33:03,955 - depth - INFO - Epoch [13][250/1514]	lr: 7.996e-05, eta: 1:47:12, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0649, loss: 0.0649, grad_norm: 0.7317
2022-04-03 19:33:21,830 - depth - INFO - Epoch [13][300/1514]	lr: 7.971e-05, eta: 1:46:54, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0618, loss: 0.0618, grad_norm: 0.6704
2022-04-03 19:33:39,740 - depth - INFO - Epoch [13][350/1514]	lr: 7.946e-05, eta: 1:46:36, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0644, loss: 0.0644, grad_norm: 0.8628
2022-04-03 19:33:57,587 - depth - INFO - Epoch [13][400/1514]	lr: 7.921e-05, eta: 1:46:18, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0639, loss: 0.0639, grad_norm: 0.8637
2022-04-03 19:34:15,420 - depth - INFO - Epoch [13][450/1514]	lr: 7.896e-05, eta: 1:46:00, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0655, loss: 0.0655, grad_norm: 0.9169
2022-04-03 19:34:33,293 - depth - INFO - Epoch [13][500/1514]	lr: 7.871e-05, eta: 1:45:42, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0656, loss: 0.0656, grad_norm: 0.9251
2022-04-03 19:34:51,173 - depth - INFO - Epoch [13][550/1514]	lr: 7.846e-05, eta: 1:45:24, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0660, loss: 0.0660, grad_norm: 0.8504
2022-04-03 19:35:09,044 - depth - INFO - Epoch [13][600/1514]	lr: 7.820e-05, eta: 1:45:06, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0670, loss: 0.0670, grad_norm: 1.0545
2022-04-03 19:35:26,886 - depth - INFO - Epoch [13][650/1514]	lr: 7.795e-05, eta: 1:44:48, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0635, loss: 0.0635, grad_norm: 0.6427
2022-04-03 19:35:44,709 - depth - INFO - Epoch [13][700/1514]	lr: 7.769e-05, eta: 1:44:30, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0624, loss: 0.0624, grad_norm: 0.8260
2022-04-03 19:36:02,592 - depth - INFO - Epoch [13][750/1514]	lr: 7.743e-05, eta: 1:44:12, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0619, loss: 0.0619, grad_norm: 0.8297
2022-04-03 19:36:20,435 - depth - INFO - Epoch [13][800/1514]	lr: 7.718e-05, eta: 1:43:54, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0625, loss: 0.0625, grad_norm: 0.6595
2022-04-03 19:36:38,297 - depth - INFO - Epoch [13][850/1514]	lr: 7.692e-05, eta: 1:43:36, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0599, loss: 0.0599, grad_norm: 0.5823
2022-04-03 19:36:56,151 - depth - INFO - Epoch [13][900/1514]	lr: 7.665e-05, eta: 1:43:18, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0598, loss: 0.0598, grad_norm: 0.5262
2022-04-03 19:37:14,024 - depth - INFO - Epoch [13][950/1514]	lr: 7.639e-05, eta: 1:43:00, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0618, loss: 0.0618, grad_norm: 0.6766
2022-04-03 19:37:31,878 - depth - INFO - Epoch [13][1000/1514]	lr: 7.613e-05, eta: 1:42:42, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0646, loss: 0.0646, grad_norm: 1.0148
2022-04-03 19:37:49,746 - depth - INFO - Epoch [13][1050/1514]	lr: 7.587e-05, eta: 1:42:24, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0636, loss: 0.0636, grad_norm: 1.0065
2022-04-03 19:38:07,622 - depth - INFO - Epoch [13][1100/1514]	lr: 7.560e-05, eta: 1:42:06, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0657, loss: 0.0657, grad_norm: 0.8778
2022-04-03 19:38:25,468 - depth - INFO - Epoch [13][1150/1514]	lr: 7.534e-05, eta: 1:41:48, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0628, loss: 0.0628, grad_norm: 0.7925
2022-04-03 19:38:43,365 - depth - INFO - Epoch [13][1200/1514]	lr: 7.507e-05, eta: 1:41:30, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0609, loss: 0.0609, grad_norm: 0.7281
2022-04-03 19:39:01,298 - depth - INFO - Epoch [13][1250/1514]	lr: 7.480e-05, eta: 1:41:12, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0624, loss: 0.0624, grad_norm: 0.9055
2022-04-03 19:39:19,182 - depth - INFO - Epoch [13][1300/1514]	lr: 7.453e-05, eta: 1:40:54, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0611, loss: 0.0611, grad_norm: 0.7544
2022-04-03 19:39:37,023 - depth - INFO - Epoch [13][1350/1514]	lr: 7.426e-05, eta: 1:40:36, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0608, loss: 0.0608, grad_norm: 0.6774
2022-04-03 19:39:54,910 - depth - INFO - Epoch [13][1400/1514]	lr: 7.399e-05, eta: 1:40:18, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0612, loss: 0.0612, grad_norm: 0.8569
2022-04-03 19:40:12,756 - depth - INFO - Epoch [13][1450/1514]	lr: 7.372e-05, eta: 1:40:00, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0594, loss: 0.0594, grad_norm: 0.6129
2022-04-03 19:40:30,615 - depth - INFO - Epoch [13][1500/1514]	lr: 7.345e-05, eta: 1:39:42, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0596, loss: 0.0596, grad_norm: 0.6426
2022-04-03 19:40:35,721 - depth - INFO - Saving checkpoint at 13 epochs
2022-04-03 19:40:56,312 - depth - INFO - Epoch [14][50/1514]	lr: 7.310e-05, eta: 1:39:16, time: 0.399, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0609, loss: 0.0609, grad_norm: 0.7132
2022-04-03 19:41:14,201 - depth - INFO - Epoch [14][100/1514]	lr: 7.283e-05, eta: 1:38:58, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0603, loss: 0.0603, grad_norm: 0.5654
2022-04-03 19:41:32,089 - depth - INFO - Epoch [14][150/1514]	lr: 7.255e-05, eta: 1:38:40, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0602, loss: 0.0602, grad_norm: 0.5865
2022-04-03 19:41:49,988 - depth - INFO - Epoch [14][200/1514]	lr: 7.228e-05, eta: 1:38:22, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0636, loss: 0.0636, grad_norm: 0.9583
2022-04-03 19:42:07,883 - depth - INFO - Epoch [14][250/1514]	lr: 7.200e-05, eta: 1:38:04, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0616, loss: 0.0616, grad_norm: 0.8865
2022-04-03 19:42:25,757 - depth - INFO - Epoch [14][300/1514]	lr: 7.172e-05, eta: 1:37:46, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0587, loss: 0.0587, grad_norm: 0.6896
2022-04-03 19:42:43,611 - depth - INFO - Epoch [14][350/1514]	lr: 7.144e-05, eta: 1:37:28, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0599, loss: 0.0599, grad_norm: 0.7546
2022-04-03 19:43:01,469 - depth - INFO - Epoch [14][400/1514]	lr: 7.116e-05, eta: 1:37:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0580, loss: 0.0580, grad_norm: 0.6257
2022-04-03 19:43:19,285 - depth - INFO - Epoch [14][450/1514]	lr: 7.088e-05, eta: 1:36:52, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0582, loss: 0.0582, grad_norm: 0.6900
2022-04-03 19:43:37,146 - depth - INFO - Epoch [14][500/1514]	lr: 7.060e-05, eta: 1:36:34, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0596, loss: 0.0596, grad_norm: 0.7967
2022-04-03 19:43:55,037 - depth - INFO - Epoch [14][550/1514]	lr: 7.032e-05, eta: 1:36:16, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0609, loss: 0.0609, grad_norm: 0.7082
2022-04-03 19:44:12,931 - depth - INFO - Epoch [14][600/1514]	lr: 7.004e-05, eta: 1:35:58, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0600, loss: 0.0600, grad_norm: 0.7801
2022-04-03 19:44:30,819 - depth - INFO - Epoch [14][650/1514]	lr: 6.976e-05, eta: 1:35:40, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0596, loss: 0.0596, grad_norm: 0.6489
2022-04-03 19:44:48,660 - depth - INFO - Epoch [14][700/1514]	lr: 6.947e-05, eta: 1:35:22, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0584, loss: 0.0584, grad_norm: 0.8224
2022-04-03 19:45:06,534 - depth - INFO - Epoch [14][750/1514]	lr: 6.919e-05, eta: 1:35:04, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0581, loss: 0.0581, grad_norm: 0.8122
2022-04-03 19:45:24,398 - depth - INFO - Epoch [14][800/1514]	lr: 6.890e-05, eta: 1:34:46, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0576, loss: 0.0576, grad_norm: 0.5841
2022-04-03 19:45:42,252 - depth - INFO - Epoch [14][850/1514]	lr: 6.861e-05, eta: 1:34:28, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0566, loss: 0.0566, grad_norm: 0.5856
2022-04-03 19:46:00,109 - depth - INFO - Epoch [14][900/1514]	lr: 6.833e-05, eta: 1:34:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0566, loss: 0.0566, grad_norm: 0.6967
2022-04-03 19:46:18,003 - depth - INFO - Epoch [14][950/1514]	lr: 6.804e-05, eta: 1:33:52, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0586, loss: 0.0586, grad_norm: 0.7774
2022-04-03 19:46:35,836 - depth - INFO - Epoch [14][1000/1514]	lr: 6.775e-05, eta: 1:33:34, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0583, loss: 0.0583, grad_norm: 0.6993
2022-04-03 19:46:53,719 - depth - INFO - Epoch [14][1050/1514]	lr: 6.746e-05, eta: 1:33:17, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0574, loss: 0.0574, grad_norm: 0.6473
2022-04-03 19:47:11,607 - depth - INFO - Epoch [14][1100/1514]	lr: 6.717e-05, eta: 1:32:59, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0585, loss: 0.0585, grad_norm: 0.7676
2022-04-03 19:47:29,509 - depth - INFO - Epoch [14][1150/1514]	lr: 6.688e-05, eta: 1:32:41, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0593, loss: 0.0593, grad_norm: 0.6383
2022-04-03 19:47:47,367 - depth - INFO - Epoch [14][1200/1514]	lr: 6.659e-05, eta: 1:32:23, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0571, loss: 0.0571, grad_norm: 0.6673
2022-04-03 19:48:05,221 - depth - INFO - Epoch [14][1250/1514]	lr: 6.630e-05, eta: 1:32:05, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0570, loss: 0.0570, grad_norm: 0.6626
2022-04-03 19:48:23,072 - depth - INFO - Epoch [14][1300/1514]	lr: 6.601e-05, eta: 1:31:47, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0572, loss: 0.0572, grad_norm: 0.7801
2022-04-03 19:48:40,921 - depth - INFO - Epoch [14][1350/1514]	lr: 6.572e-05, eta: 1:31:29, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0573, loss: 0.0573, grad_norm: 0.6778
2022-04-03 19:48:58,833 - depth - INFO - Epoch [14][1400/1514]	lr: 6.542e-05, eta: 1:31:11, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0580, loss: 0.0580, grad_norm: 0.7320
2022-04-03 19:49:16,740 - depth - INFO - Epoch [14][1450/1514]	lr: 6.513e-05, eta: 1:30:53, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0571, loss: 0.0571, grad_norm: 0.7560
2022-04-03 19:49:34,606 - depth - INFO - Epoch [14][1500/1514]	lr: 6.483e-05, eta: 1:30:35, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0571, loss: 0.0571, grad_norm: 0.7172
2022-04-03 19:49:39,720 - depth - INFO - Saving checkpoint at 14 epochs
2022-04-03 19:50:00,343 - depth - INFO - Epoch [15][50/1514]	lr: 6.446e-05, eta: 1:30:10, time: 0.399, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0576, loss: 0.0576, grad_norm: 0.5355
2022-04-03 19:50:18,262 - depth - INFO - Epoch [15][100/1514]	lr: 6.416e-05, eta: 1:29:52, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0563, loss: 0.0563, grad_norm: 0.5821
2022-04-03 19:50:36,158 - depth - INFO - Epoch [15][150/1514]	lr: 6.386e-05, eta: 1:29:34, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0563, loss: 0.0563, grad_norm: 0.7343
2022-04-03 19:50:54,049 - depth - INFO - Epoch [15][200/1514]	lr: 6.357e-05, eta: 1:29:16, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0593, loss: 0.0593, grad_norm: 0.9128
2022-04-03 19:51:11,907 - depth - INFO - Epoch [15][250/1514]	lr: 6.327e-05, eta: 1:28:58, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0569, loss: 0.0569, grad_norm: 0.8401
2022-04-03 19:51:29,788 - depth - INFO - Epoch [15][300/1514]	lr: 6.297e-05, eta: 1:28:40, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0539, loss: 0.0539, grad_norm: 0.4554
2022-04-03 19:51:47,639 - depth - INFO - Epoch [15][350/1514]	lr: 6.267e-05, eta: 1:28:22, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0542, loss: 0.0542, grad_norm: 0.5208
2022-04-03 19:52:05,509 - depth - INFO - Epoch [15][400/1514]	lr: 6.238e-05, eta: 1:28:04, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0544, loss: 0.0544, grad_norm: 0.6445
2022-04-03 19:52:23,332 - depth - INFO - Epoch [15][450/1514]	lr: 6.208e-05, eta: 1:27:46, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0558, loss: 0.0558, grad_norm: 0.6364
2022-04-03 19:52:41,185 - depth - INFO - Epoch [15][500/1514]	lr: 6.178e-05, eta: 1:27:28, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0561, loss: 0.0561, grad_norm: 0.8110
2022-04-03 19:52:59,097 - depth - INFO - Epoch [15][550/1514]	lr: 6.148e-05, eta: 1:27:10, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0586, loss: 0.0586, grad_norm: 1.0438
2022-04-03 19:53:17,001 - depth - INFO - Epoch [15][600/1514]	lr: 6.118e-05, eta: 1:26:52, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0600, loss: 0.0600, grad_norm: 1.2368
2022-04-03 19:53:34,879 - depth - INFO - Epoch [15][650/1514]	lr: 6.087e-05, eta: 1:26:34, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0587, loss: 0.0587, grad_norm: 1.0431
2022-04-03 19:53:52,725 - depth - INFO - Epoch [15][700/1514]	lr: 6.057e-05, eta: 1:26:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0582, loss: 0.0582, grad_norm: 1.0167
2022-04-03 19:54:10,628 - depth - INFO - Epoch [15][750/1514]	lr: 6.027e-05, eta: 1:25:58, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0551, loss: 0.0551, grad_norm: 0.5001
2022-04-03 19:54:28,455 - depth - INFO - Epoch [15][800/1514]	lr: 5.997e-05, eta: 1:25:40, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0553, loss: 0.0553, grad_norm: 0.5788
2022-04-03 19:54:46,286 - depth - INFO - Epoch [15][850/1514]	lr: 5.967e-05, eta: 1:25:22, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0539, loss: 0.0539, grad_norm: 0.6828
2022-04-03 19:55:04,125 - depth - INFO - Epoch [15][900/1514]	lr: 5.936e-05, eta: 1:25:04, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0558, loss: 0.0558, grad_norm: 1.0675
2022-04-03 19:55:21,971 - depth - INFO - Epoch [15][950/1514]	lr: 5.906e-05, eta: 1:24:46, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0558, loss: 0.0558, grad_norm: 0.7739
2022-04-03 19:55:39,827 - depth - INFO - Epoch [15][1000/1514]	lr: 5.876e-05, eta: 1:24:28, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0541, loss: 0.0541, grad_norm: 0.7443
2022-04-03 19:55:57,671 - depth - INFO - Epoch [15][1050/1514]	lr: 5.845e-05, eta: 1:24:10, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0535, loss: 0.0535, grad_norm: 0.6788
2022-04-03 19:56:15,552 - depth - INFO - Epoch [15][1100/1514]	lr: 5.815e-05, eta: 1:23:52, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0554, loss: 0.0554, grad_norm: 0.6582
2022-04-03 19:56:33,377 - depth - INFO - Epoch [15][1150/1514]	lr: 5.784e-05, eta: 1:23:34, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0548, loss: 0.0548, grad_norm: 0.5181
2022-04-03 19:56:51,244 - depth - INFO - Epoch [15][1200/1514]	lr: 5.754e-05, eta: 1:23:16, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0554, loss: 0.0554, grad_norm: 0.8756
2022-04-03 19:57:09,132 - depth - INFO - Epoch [15][1250/1514]	lr: 5.723e-05, eta: 1:22:59, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0535, loss: 0.0535, grad_norm: 0.6752
2022-04-03 19:57:26,970 - depth - INFO - Epoch [15][1300/1514]	lr: 5.693e-05, eta: 1:22:41, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0543, loss: 0.0543, grad_norm: 0.6604
2022-04-03 19:57:44,839 - depth - INFO - Epoch [15][1350/1514]	lr: 5.662e-05, eta: 1:22:23, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0544, loss: 0.0544, grad_norm: 0.9362
2022-04-03 19:58:02,760 - depth - INFO - Epoch [15][1400/1514]	lr: 5.631e-05, eta: 1:22:05, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0566, loss: 0.0566, grad_norm: 0.9984
2022-04-03 19:58:20,627 - depth - INFO - Epoch [15][1450/1514]	lr: 5.601e-05, eta: 1:21:47, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0542, loss: 0.0542, grad_norm: 0.8102
2022-04-03 19:58:38,511 - depth - INFO - Epoch [15][1500/1514]	lr: 5.570e-05, eta: 1:21:29, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0535, loss: 0.0535, grad_norm: 0.8088
2022-04-03 19:58:43,627 - depth - INFO - Saving checkpoint at 15 epochs
2022-04-03 19:59:04,263 - depth - INFO - Epoch [16][50/1514]	lr: 5.531e-05, eta: 1:21:04, time: 0.400, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0535, loss: 0.0535, grad_norm: 0.5919
2022-04-03 19:59:22,113 - depth - INFO - Epoch [16][100/1514]	lr: 5.500e-05, eta: 1:20:46, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0520, loss: 0.0520, grad_norm: 0.5006
2022-04-03 19:59:39,986 - depth - INFO - Epoch [16][150/1514]	lr: 5.469e-05, eta: 1:20:28, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0553, loss: 0.0553, grad_norm: 1.1219
2022-04-03 19:59:57,859 - depth - INFO - Epoch [16][200/1514]	lr: 5.439e-05, eta: 1:20:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0559, loss: 0.0559, grad_norm: 0.8094
2022-04-03 20:00:15,751 - depth - INFO - Epoch [16][250/1514]	lr: 5.408e-05, eta: 1:19:52, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0529, loss: 0.0529, grad_norm: 0.4921
2022-04-03 20:00:33,653 - depth - INFO - Epoch [16][300/1514]	lr: 5.377e-05, eta: 1:19:34, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0516, loss: 0.0516, grad_norm: 0.5536
2022-04-03 20:00:51,528 - depth - INFO - Epoch [16][350/1514]	lr: 5.346e-05, eta: 1:19:16, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0522, loss: 0.0522, grad_norm: 0.5758
2022-04-03 20:01:09,369 - depth - INFO - Epoch [16][400/1514]	lr: 5.316e-05, eta: 1:18:58, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0519, loss: 0.0519, grad_norm: 0.5545
2022-04-03 20:01:27,199 - depth - INFO - Epoch [16][450/1514]	lr: 5.285e-05, eta: 1:18:40, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0524, loss: 0.0524, grad_norm: 0.6685
2022-04-03 20:01:45,084 - depth - INFO - Epoch [16][500/1514]	lr: 5.254e-05, eta: 1:18:23, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0532, loss: 0.0532, grad_norm: 0.8270
2022-04-03 20:02:02,996 - depth - INFO - Epoch [16][550/1514]	lr: 5.223e-05, eta: 1:18:05, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0561, loss: 0.0561, grad_norm: 1.1692
2022-04-03 20:02:20,920 - depth - INFO - Epoch [16][600/1514]	lr: 5.192e-05, eta: 1:17:47, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0556, loss: 0.0556, grad_norm: 1.0974
2022-04-03 20:02:38,836 - depth - INFO - Epoch [16][650/1514]	lr: 5.161e-05, eta: 1:17:29, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0542, loss: 0.0542, grad_norm: 0.7142
2022-04-03 20:02:56,662 - depth - INFO - Epoch [16][700/1514]	lr: 5.131e-05, eta: 1:17:11, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0526, loss: 0.0526, grad_norm: 0.7776
2022-04-03 20:03:14,576 - depth - INFO - Epoch [16][750/1514]	lr: 5.100e-05, eta: 1:16:53, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0505, loss: 0.0505, grad_norm: 0.4399
2022-04-03 20:03:32,431 - depth - INFO - Epoch [16][800/1514]	lr: 5.069e-05, eta: 1:16:35, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0513, loss: 0.0513, grad_norm: 0.5343
2022-04-03 20:03:50,295 - depth - INFO - Epoch [16][850/1514]	lr: 5.038e-05, eta: 1:16:17, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0511, loss: 0.0511, grad_norm: 0.8843
2022-04-03 20:04:08,183 - depth - INFO - Epoch [16][900/1514]	lr: 5.007e-05, eta: 1:15:59, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0529, loss: 0.0529, grad_norm: 1.1793
2022-04-03 20:04:26,047 - depth - INFO - Epoch [16][950/1514]	lr: 4.976e-05, eta: 1:15:41, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0529, loss: 0.0529, grad_norm: 1.0355
2022-04-03 20:04:43,896 - depth - INFO - Epoch [16][1000/1514]	lr: 4.945e-05, eta: 1:15:23, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0506, loss: 0.0506, grad_norm: 0.6180
2022-04-03 20:05:01,754 - depth - INFO - Epoch [16][1050/1514]	lr: 4.915e-05, eta: 1:15:05, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0497, loss: 0.0497, grad_norm: 0.5571
2022-04-03 20:05:19,633 - depth - INFO - Epoch [16][1100/1514]	lr: 4.884e-05, eta: 1:14:47, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0520, loss: 0.0520, grad_norm: 0.6868
2022-04-03 20:05:37,485 - depth - INFO - Epoch [16][1150/1514]	lr: 4.853e-05, eta: 1:14:29, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0519, loss: 0.0519, grad_norm: 0.7443
2022-04-03 20:05:55,331 - depth - INFO - Epoch [16][1200/1514]	lr: 4.822e-05, eta: 1:14:11, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0506, loss: 0.0506, grad_norm: 0.7015
2022-04-03 20:06:13,213 - depth - INFO - Epoch [16][1250/1514]	lr: 4.791e-05, eta: 1:13:54, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0509, loss: 0.0509, grad_norm: 0.5600
2022-04-03 20:06:31,073 - depth - INFO - Epoch [16][1300/1514]	lr: 4.760e-05, eta: 1:13:36, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0518, loss: 0.0518, grad_norm: 0.8301
2022-04-03 20:06:48,932 - depth - INFO - Epoch [16][1350/1514]	lr: 4.730e-05, eta: 1:13:18, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0527, loss: 0.0527, grad_norm: 1.0163
2022-04-03 20:07:06,806 - depth - INFO - Epoch [16][1400/1514]	lr: 4.699e-05, eta: 1:13:00, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0518, loss: 0.0518, grad_norm: 0.6971
2022-04-03 20:07:24,647 - depth - INFO - Epoch [16][1450/1514]	lr: 4.668e-05, eta: 1:12:42, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0500, loss: 0.0500, grad_norm: 0.5692
2022-04-03 20:07:42,511 - depth - INFO - Epoch [16][1500/1514]	lr: 4.637e-05, eta: 1:12:24, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0500, loss: 0.0500, grad_norm: 0.7060
2022-04-03 20:07:47,614 - depth - INFO - Saving checkpoint at 16 epochs
2022-04-03 20:08:08,273 - depth - INFO - Epoch [17][50/1514]	lr: 4.598e-05, eta: 1:11:59, time: 0.400, data_time: 0.051, memory: 15394, decode.loss_depth: 0.0499, loss: 0.0499, grad_norm: 0.5637
2022-04-03 20:08:26,145 - depth - INFO - Epoch [17][100/1514]	lr: 4.567e-05, eta: 1:11:42, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0496, loss: 0.0496, grad_norm: 0.5880
2022-04-03 20:08:44,008 - depth - INFO - Epoch [17][150/1514]	lr: 4.536e-05, eta: 1:11:24, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0521, loss: 0.0521, grad_norm: 1.0140
2022-04-03 20:09:01,903 - depth - INFO - Epoch [17][200/1514]	lr: 4.506e-05, eta: 1:11:06, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0518, loss: 0.0518, grad_norm: 0.7012
2022-04-03 20:09:19,782 - depth - INFO - Epoch [17][250/1514]	lr: 4.475e-05, eta: 1:10:48, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0499, loss: 0.0499, grad_norm: 0.5168
2022-04-03 20:09:37,676 - depth - INFO - Epoch [17][300/1514]	lr: 4.444e-05, eta: 1:10:30, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0478, loss: 0.0478, grad_norm: 0.4611
2022-04-03 20:09:55,546 - depth - INFO - Epoch [17][350/1514]	lr: 4.413e-05, eta: 1:10:12, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0487, loss: 0.0487, grad_norm: 0.6392
2022-04-03 20:10:13,396 - depth - INFO - Epoch [17][400/1514]	lr: 4.383e-05, eta: 1:09:54, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0494, loss: 0.0494, grad_norm: 0.5473
2022-04-03 20:10:31,234 - depth - INFO - Epoch [17][450/1514]	lr: 4.352e-05, eta: 1:09:36, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0509, loss: 0.0509, grad_norm: 0.7738
2022-04-03 20:10:49,092 - depth - INFO - Epoch [17][500/1514]	lr: 4.322e-05, eta: 1:09:18, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0496, loss: 0.0496, grad_norm: 0.6611
2022-04-03 20:11:06,921 - depth - INFO - Epoch [17][550/1514]	lr: 4.291e-05, eta: 1:09:00, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0507, loss: 0.0507, grad_norm: 0.6798
2022-04-03 20:11:24,818 - depth - INFO - Epoch [17][600/1514]	lr: 4.261e-05, eta: 1:08:42, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0496, loss: 0.0496, grad_norm: 0.7995
2022-04-03 20:11:42,702 - depth - INFO - Epoch [17][650/1514]	lr: 4.230e-05, eta: 1:08:24, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0492, loss: 0.0492, grad_norm: 0.6410
2022-04-03 20:12:00,572 - depth - INFO - Epoch [17][700/1514]	lr: 4.200e-05, eta: 1:08:06, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0488, loss: 0.0488, grad_norm: 0.6554
2022-04-03 20:12:18,466 - depth - INFO - Epoch [17][750/1514]	lr: 4.169e-05, eta: 1:07:49, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0478, loss: 0.0478, grad_norm: 0.3976
2022-04-03 20:12:36,327 - depth - INFO - Epoch [17][800/1514]	lr: 4.139e-05, eta: 1:07:31, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0480, loss: 0.0480, grad_norm: 0.4401
2022-04-03 20:12:54,240 - depth - INFO - Epoch [17][850/1514]	lr: 4.108e-05, eta: 1:07:13, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0472, loss: 0.0472, grad_norm: 0.6001
2022-04-03 20:13:12,070 - depth - INFO - Epoch [17][900/1514]	lr: 4.078e-05, eta: 1:06:55, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0492, loss: 0.0492, grad_norm: 1.0194
2022-04-03 20:13:29,943 - depth - INFO - Epoch [17][950/1514]	lr: 4.048e-05, eta: 1:06:37, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0491, loss: 0.0491, grad_norm: 0.6999
2022-04-03 20:13:47,780 - depth - INFO - Epoch [17][1000/1514]	lr: 4.017e-05, eta: 1:06:19, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0477, loss: 0.0477, grad_norm: 0.4991
2022-04-03 20:14:05,670 - depth - INFO - Epoch [17][1050/1514]	lr: 3.987e-05, eta: 1:06:01, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0474, loss: 0.0474, grad_norm: 0.5751
2022-04-03 20:14:23,538 - depth - INFO - Epoch [17][1100/1514]	lr: 3.957e-05, eta: 1:05:43, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0489, loss: 0.0489, grad_norm: 0.5588
2022-04-03 20:14:41,385 - depth - INFO - Epoch [17][1150/1514]	lr: 3.927e-05, eta: 1:05:25, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0495, loss: 0.0495, grad_norm: 0.7241
2022-04-03 20:14:59,273 - depth - INFO - Epoch [17][1200/1514]	lr: 3.897e-05, eta: 1:05:07, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0480, loss: 0.0480, grad_norm: 0.7590
2022-04-03 20:15:17,174 - depth - INFO - Epoch [17][1250/1514]	lr: 3.867e-05, eta: 1:04:49, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0479, loss: 0.0479, grad_norm: 0.5059
2022-04-03 20:15:35,046 - depth - INFO - Epoch [17][1300/1514]	lr: 3.836e-05, eta: 1:04:31, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0484, loss: 0.0484, grad_norm: 0.5814
2022-04-03 20:15:52,928 - depth - INFO - Epoch [17][1350/1514]	lr: 3.806e-05, eta: 1:04:13, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0475, loss: 0.0475, grad_norm: 0.6892
2022-04-03 20:16:10,796 - depth - INFO - Epoch [17][1400/1514]	lr: 3.777e-05, eta: 1:03:56, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0478, loss: 0.0478, grad_norm: 0.4522
2022-04-03 20:16:28,652 - depth - INFO - Epoch [17][1450/1514]	lr: 3.747e-05, eta: 1:03:38, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0460, loss: 0.0460, grad_norm: 0.5119
2022-04-03 20:16:46,496 - depth - INFO - Epoch [17][1500/1514]	lr: 3.717e-05, eta: 1:03:20, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0458, loss: 0.0458, grad_norm: 0.4602
2022-04-03 20:16:51,583 - depth - INFO - Saving checkpoint at 17 epochs
2022-04-03 20:17:12,194 - depth - INFO - Epoch [18][50/1514]	lr: 3.679e-05, eta: 1:02:56, time: 0.399, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0473, loss: 0.0473, grad_norm: 0.7035
2022-04-03 20:17:30,068 - depth - INFO - Epoch [18][100/1514]	lr: 3.649e-05, eta: 1:02:38, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0474, loss: 0.0474, grad_norm: 0.7188
2022-04-03 20:17:47,970 - depth - INFO - Epoch [18][150/1514]	lr: 3.619e-05, eta: 1:02:20, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0499, loss: 0.0499, grad_norm: 0.9754
2022-04-03 20:18:05,857 - depth - INFO - Epoch [18][200/1514]	lr: 3.590e-05, eta: 1:02:02, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0491, loss: 0.0491, grad_norm: 0.5323
2022-04-03 20:18:23,751 - depth - INFO - Epoch [18][250/1514]	lr: 3.560e-05, eta: 1:01:44, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0475, loss: 0.0475, grad_norm: 0.6057
2022-04-03 20:18:41,641 - depth - INFO - Epoch [18][300/1514]	lr: 3.530e-05, eta: 1:01:26, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0456, loss: 0.0456, grad_norm: 0.5213
2022-04-03 20:18:59,530 - depth - INFO - Epoch [18][350/1514]	lr: 3.501e-05, eta: 1:01:08, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0454, loss: 0.0454, grad_norm: 0.5678
2022-04-03 20:19:17,358 - depth - INFO - Epoch [18][400/1514]	lr: 3.472e-05, eta: 1:00:50, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0467, loss: 0.0467, grad_norm: 0.5201
2022-04-03 20:19:35,182 - depth - INFO - Epoch [18][450/1514]	lr: 3.442e-05, eta: 1:00:32, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0469, loss: 0.0469, grad_norm: 0.5985
2022-04-03 20:19:52,978 - depth - INFO - Epoch [18][500/1514]	lr: 3.413e-05, eta: 1:00:14, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0466, loss: 0.0466, grad_norm: 0.5040
2022-04-03 20:20:10,875 - depth - INFO - Epoch [18][550/1514]	lr: 3.384e-05, eta: 0:59:56, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0481, loss: 0.0481, grad_norm: 0.6635
2022-04-03 20:20:28,784 - depth - INFO - Epoch [18][600/1514]	lr: 3.355e-05, eta: 0:59:39, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0467, loss: 0.0467, grad_norm: 0.5092
2022-04-03 20:20:46,655 - depth - INFO - Epoch [18][650/1514]	lr: 3.325e-05, eta: 0:59:21, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0467, loss: 0.0467, grad_norm: 0.5727
2022-04-03 20:21:04,460 - depth - INFO - Epoch [18][700/1514]	lr: 3.296e-05, eta: 0:59:03, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0468, loss: 0.0468, grad_norm: 0.7991
2022-04-03 20:21:22,360 - depth - INFO - Epoch [18][750/1514]	lr: 3.267e-05, eta: 0:58:45, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0451, loss: 0.0451, grad_norm: 0.4213
2022-04-03 20:21:40,206 - depth - INFO - Epoch [18][800/1514]	lr: 3.238e-05, eta: 0:58:27, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0460, loss: 0.0460, grad_norm: 0.5052
2022-04-03 20:21:58,072 - depth - INFO - Epoch [18][850/1514]	lr: 3.210e-05, eta: 0:58:09, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0453, loss: 0.0453, grad_norm: 0.6505
2022-04-03 20:22:15,916 - depth - INFO - Epoch [18][900/1514]	lr: 3.181e-05, eta: 0:57:51, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0463, loss: 0.0463, grad_norm: 0.7852
2022-04-03 20:22:33,788 - depth - INFO - Epoch [18][950/1514]	lr: 3.152e-05, eta: 0:57:33, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0458, loss: 0.0458, grad_norm: 0.5088
2022-04-03 20:22:51,635 - depth - INFO - Epoch [18][1000/1514]	lr: 3.124e-05, eta: 0:57:15, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0453, loss: 0.0453, grad_norm: 0.4883
2022-04-03 20:23:09,520 - depth - INFO - Epoch [18][1050/1514]	lr: 3.095e-05, eta: 0:56:57, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0441, loss: 0.0441, grad_norm: 0.4836
2022-04-03 20:23:27,395 - depth - INFO - Epoch [18][1100/1514]	lr: 3.066e-05, eta: 0:56:39, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0456, loss: 0.0456, grad_norm: 0.4098
2022-04-03 20:23:45,328 - depth - INFO - Epoch [18][1150/1514]	lr: 3.038e-05, eta: 0:56:22, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0466, loss: 0.0466, grad_norm: 0.6742
2022-04-03 20:24:03,260 - depth - INFO - Epoch [18][1200/1514]	lr: 3.010e-05, eta: 0:56:04, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0448, loss: 0.0448, grad_norm: 0.6051
2022-04-03 20:24:21,189 - depth - INFO - Epoch [18][1250/1514]	lr: 2.981e-05, eta: 0:55:46, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0457, loss: 0.0457, grad_norm: 0.6112
2022-04-03 20:24:39,101 - depth - INFO - Epoch [18][1300/1514]	lr: 2.953e-05, eta: 0:55:28, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0455, loss: 0.0455, grad_norm: 0.5625
2022-04-03 20:24:56,974 - depth - INFO - Epoch [18][1350/1514]	lr: 2.925e-05, eta: 0:55:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0445, loss: 0.0445, grad_norm: 0.6207
2022-04-03 20:25:14,846 - depth - INFO - Epoch [18][1400/1514]	lr: 2.897e-05, eta: 0:54:52, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0447, loss: 0.0447, grad_norm: 0.4298
2022-04-03 20:25:32,699 - depth - INFO - Epoch [18][1450/1514]	lr: 2.869e-05, eta: 0:54:34, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0439, loss: 0.0439, grad_norm: 0.4542
2022-04-03 20:25:50,561 - depth - INFO - Epoch [18][1500/1514]	lr: 2.841e-05, eta: 0:54:16, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0439, loss: 0.0439, grad_norm: 0.4722
2022-04-03 20:25:55,689 - depth - INFO - Saving checkpoint at 18 epochs
2022-04-03 20:26:15,150 - depth - INFO - Summary:
2022-04-03 20:26:15,150 - depth - INFO - 
+-------+--------+--------+---------+--------+--------+----------+---------+--------+
|   a1  |   a2   |   a3   | abs_rel |  rmse  | log_10 | rmse_log |  silog  | sq_rel |
+-------+--------+--------+---------+--------+--------+----------+---------+--------+
| 0.872 | 0.9785 | 0.9959 |  0.1147 | 0.4036 | 0.0489 |  0.1458  | 11.8233 | 0.068  |
+-------+--------+--------+---------+--------+--------+----------+---------+--------+
2022-04-03 20:26:15,151 - depth - INFO - Exp name: bts_r50_nyu_24e.py
2022-04-03 20:26:15,151 - depth - INFO - Epoch(val) [18][327]	a1: 0.8720, a2: 0.9785, a3: 0.9959, abs_rel: 0.1146639809012413, rmse: 0.40361008048057556, log_10: 0.04885505512356758, rmse_log: 0.1457773894071579, silog: 11.8233, sq_rel: 0.0679706260561943
2022-04-03 20:26:35,580 - depth - INFO - Epoch [19][50/1514]	lr: 2.806e-05, eta: 0:53:53, time: 0.409, data_time: 0.054, memory: 15394, decode.loss_depth: 0.0454, loss: 0.0454, grad_norm: 0.7774
2022-04-03 20:26:53,444 - depth - INFO - Epoch [19][100/1514]	lr: 2.778e-05, eta: 0:53:35, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0446, loss: 0.0446, grad_norm: 0.4560
2022-04-03 20:27:11,345 - depth - INFO - Epoch [19][150/1514]	lr: 2.750e-05, eta: 0:53:17, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0458, loss: 0.0458, grad_norm: 0.6678
2022-04-03 20:27:29,227 - depth - INFO - Epoch [19][200/1514]	lr: 2.723e-05, eta: 0:52:59, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0461, loss: 0.0461, grad_norm: 0.4483
2022-04-03 20:27:47,103 - depth - INFO - Epoch [19][250/1514]	lr: 2.695e-05, eta: 0:52:41, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0448, loss: 0.0448, grad_norm: 0.6206
2022-04-03 20:28:04,986 - depth - INFO - Epoch [19][300/1514]	lr: 2.668e-05, eta: 0:52:23, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0431, loss: 0.0431, grad_norm: 0.5920
2022-04-03 20:28:22,852 - depth - INFO - Epoch [19][350/1514]	lr: 2.641e-05, eta: 0:52:05, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0435, loss: 0.0435, grad_norm: 0.5247
2022-04-03 20:28:40,734 - depth - INFO - Epoch [19][400/1514]	lr: 2.614e-05, eta: 0:51:47, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0430, loss: 0.0430, grad_norm: 0.4110
2022-04-03 20:28:58,517 - depth - INFO - Epoch [19][450/1514]	lr: 2.587e-05, eta: 0:51:29, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0436, loss: 0.0436, grad_norm: 0.4422
2022-04-03 20:29:16,372 - depth - INFO - Epoch [19][500/1514]	lr: 2.560e-05, eta: 0:51:11, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0439, loss: 0.0439, grad_norm: 0.5486
2022-04-03 20:29:34,260 - depth - INFO - Epoch [19][550/1514]	lr: 2.533e-05, eta: 0:50:53, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0454, loss: 0.0454, grad_norm: 0.6397
2022-04-03 20:29:52,132 - depth - INFO - Epoch [19][600/1514]	lr: 2.506e-05, eta: 0:50:36, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0437, loss: 0.0437, grad_norm: 0.4780
2022-04-03 20:30:09,995 - depth - INFO - Epoch [19][650/1514]	lr: 2.479e-05, eta: 0:50:18, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0440, loss: 0.0440, grad_norm: 0.3669
2022-04-03 20:30:27,806 - depth - INFO - Epoch [19][700/1514]	lr: 2.453e-05, eta: 0:50:00, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0445, loss: 0.0445, grad_norm: 0.5757
2022-04-03 20:30:45,687 - depth - INFO - Epoch [19][750/1514]	lr: 2.426e-05, eta: 0:49:42, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0442, loss: 0.0442, grad_norm: 0.6911
2022-04-03 20:31:03,562 - depth - INFO - Epoch [19][800/1514]	lr: 2.400e-05, eta: 0:49:24, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0438, loss: 0.0438, grad_norm: 0.5281
2022-04-03 20:31:21,423 - depth - INFO - Epoch [19][850/1514]	lr: 2.373e-05, eta: 0:49:06, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0426, loss: 0.0426, grad_norm: 0.5471
2022-04-03 20:31:39,291 - depth - INFO - Epoch [19][900/1514]	lr: 2.347e-05, eta: 0:48:48, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0432, loss: 0.0432, grad_norm: 0.5989
2022-04-03 20:31:57,169 - depth - INFO - Epoch [19][950/1514]	lr: 2.321e-05, eta: 0:48:30, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0433, loss: 0.0433, grad_norm: 0.3832
2022-04-03 20:32:15,045 - depth - INFO - Epoch [19][1000/1514]	lr: 2.295e-05, eta: 0:48:12, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0429, loss: 0.0429, grad_norm: 0.4930
2022-04-03 20:32:32,895 - depth - INFO - Epoch [19][1050/1514]	lr: 2.269e-05, eta: 0:47:54, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0422, loss: 0.0422, grad_norm: 0.4688
2022-04-03 20:32:50,761 - depth - INFO - Epoch [19][1100/1514]	lr: 2.244e-05, eta: 0:47:37, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0437, loss: 0.0437, grad_norm: 0.4612
2022-04-03 20:33:08,615 - depth - INFO - Epoch [19][1150/1514]	lr: 2.218e-05, eta: 0:47:19, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0451, loss: 0.0451, grad_norm: 0.8263
2022-04-03 20:33:26,466 - depth - INFO - Epoch [19][1200/1514]	lr: 2.192e-05, eta: 0:47:01, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0429, loss: 0.0429, grad_norm: 0.4783
2022-04-03 20:33:44,365 - depth - INFO - Epoch [19][1250/1514]	lr: 2.167e-05, eta: 0:46:43, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0430, loss: 0.0430, grad_norm: 0.3347
2022-04-03 20:34:02,213 - depth - INFO - Epoch [19][1300/1514]	lr: 2.141e-05, eta: 0:46:25, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0443, loss: 0.0443, grad_norm: 0.7471
2022-04-03 20:34:20,091 - depth - INFO - Epoch [19][1350/1514]	lr: 2.116e-05, eta: 0:46:07, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0432, loss: 0.0432, grad_norm: 0.6180
2022-04-03 20:34:37,996 - depth - INFO - Epoch [19][1400/1514]	lr: 2.091e-05, eta: 0:45:49, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0438, loss: 0.0438, grad_norm: 0.6248
2022-04-03 20:34:55,851 - depth - INFO - Epoch [19][1450/1514]	lr: 2.066e-05, eta: 0:45:31, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.3793
2022-04-03 20:35:13,701 - depth - INFO - Epoch [19][1500/1514]	lr: 2.041e-05, eta: 0:45:13, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.4504
2022-04-03 20:35:18,824 - depth - INFO - Saving checkpoint at 19 epochs
2022-04-03 20:35:39,428 - depth - INFO - Epoch [20][50/1514]	lr: 2.009e-05, eta: 0:44:50, time: 0.399, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0426, loss: 0.0426, grad_norm: 0.6110
2022-04-03 20:35:57,307 - depth - INFO - Epoch [20][100/1514]	lr: 1.985e-05, eta: 0:44:32, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0431, loss: 0.0431, grad_norm: 0.5186
2022-04-03 20:36:15,161 - depth - INFO - Epoch [20][150/1514]	lr: 1.960e-05, eta: 0:44:14, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0431, loss: 0.0431, grad_norm: 0.5744
2022-04-03 20:36:33,049 - depth - INFO - Epoch [20][200/1514]	lr: 1.936e-05, eta: 0:43:56, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0442, loss: 0.0442, grad_norm: 0.5275
2022-04-03 20:36:50,904 - depth - INFO - Epoch [20][250/1514]	lr: 1.911e-05, eta: 0:43:38, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0429, loss: 0.0429, grad_norm: 0.6382
2022-04-03 20:37:08,756 - depth - INFO - Epoch [20][300/1514]	lr: 1.887e-05, eta: 0:43:20, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0408, loss: 0.0408, grad_norm: 0.3809
2022-04-03 20:37:26,640 - depth - INFO - Epoch [20][350/1514]	lr: 1.863e-05, eta: 0:43:02, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0410, loss: 0.0410, grad_norm: 0.4327
2022-04-03 20:37:44,498 - depth - INFO - Epoch [20][400/1514]	lr: 1.839e-05, eta: 0:42:44, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0414, loss: 0.0414, grad_norm: 0.3584
2022-04-03 20:38:02,349 - depth - INFO - Epoch [20][450/1514]	lr: 1.815e-05, eta: 0:42:27, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0422, loss: 0.0422, grad_norm: 0.4563
2022-04-03 20:38:20,245 - depth - INFO - Epoch [20][500/1514]	lr: 1.792e-05, eta: 0:42:09, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0419, loss: 0.0419, grad_norm: 0.5287
2022-04-03 20:38:38,150 - depth - INFO - Epoch [20][550/1514]	lr: 1.768e-05, eta: 0:41:51, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0435, loss: 0.0435, grad_norm: 0.4272
2022-04-03 20:38:56,060 - depth - INFO - Epoch [20][600/1514]	lr: 1.744e-05, eta: 0:41:33, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.3619
2022-04-03 20:39:13,944 - depth - INFO - Epoch [20][650/1514]	lr: 1.721e-05, eta: 0:41:15, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.4585
2022-04-03 20:39:31,791 - depth - INFO - Epoch [20][700/1514]	lr: 1.698e-05, eta: 0:40:57, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0424, loss: 0.0424, grad_norm: 0.6326
2022-04-03 20:39:49,710 - depth - INFO - Epoch [20][750/1514]	lr: 1.675e-05, eta: 0:40:39, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0424, loss: 0.0424, grad_norm: 0.6546
2022-04-03 20:40:07,563 - depth - INFO - Epoch [20][800/1514]	lr: 1.652e-05, eta: 0:40:21, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.4345
2022-04-03 20:40:25,448 - depth - INFO - Epoch [20][850/1514]	lr: 1.629e-05, eta: 0:40:03, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0408, loss: 0.0408, grad_norm: 0.3761
2022-04-03 20:40:43,321 - depth - INFO - Epoch [20][900/1514]	lr: 1.606e-05, eta: 0:39:46, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0408, loss: 0.0408, grad_norm: 0.3011
2022-04-03 20:41:01,223 - depth - INFO - Epoch [20][950/1514]	lr: 1.584e-05, eta: 0:39:28, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0416, loss: 0.0416, grad_norm: 0.3923
2022-04-03 20:41:19,103 - depth - INFO - Epoch [20][1000/1514]	lr: 1.561e-05, eta: 0:39:10, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0412, loss: 0.0412, grad_norm: 0.4108
2022-04-03 20:41:36,965 - depth - INFO - Epoch [20][1050/1514]	lr: 1.539e-05, eta: 0:38:52, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0406, loss: 0.0406, grad_norm: 0.4411
2022-04-03 20:41:54,837 - depth - INFO - Epoch [20][1100/1514]	lr: 1.517e-05, eta: 0:38:34, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0422, loss: 0.0422, grad_norm: 0.4831
2022-04-03 20:42:12,691 - depth - INFO - Epoch [20][1150/1514]	lr: 1.495e-05, eta: 0:38:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0430, loss: 0.0430, grad_norm: 0.6115
2022-04-03 20:42:30,562 - depth - INFO - Epoch [20][1200/1514]	lr: 1.473e-05, eta: 0:37:58, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0408, loss: 0.0408, grad_norm: 0.4522
2022-04-03 20:42:48,453 - depth - INFO - Epoch [20][1250/1514]	lr: 1.451e-05, eta: 0:37:40, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0416, loss: 0.0416, grad_norm: 0.3976
2022-04-03 20:43:06,356 - depth - INFO - Epoch [20][1300/1514]	lr: 1.429e-05, eta: 0:37:22, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.5717
2022-04-03 20:43:24,254 - depth - INFO - Epoch [20][1350/1514]	lr: 1.408e-05, eta: 0:37:05, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0411, loss: 0.0411, grad_norm: 0.3638
2022-04-03 20:43:42,142 - depth - INFO - Epoch [20][1400/1514]	lr: 1.386e-05, eta: 0:36:47, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0414, loss: 0.0414, grad_norm: 0.4377
2022-04-03 20:44:00,009 - depth - INFO - Epoch [20][1450/1514]	lr: 1.365e-05, eta: 0:36:29, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0405, loss: 0.0405, grad_norm: 0.4226
2022-04-03 20:44:17,856 - depth - INFO - Epoch [20][1500/1514]	lr: 1.344e-05, eta: 0:36:11, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0403, loss: 0.0403, grad_norm: 0.5645
2022-04-03 20:44:22,983 - depth - INFO - Saving checkpoint at 20 epochs
2022-04-03 20:44:43,627 - depth - INFO - Epoch [21][50/1514]	lr: 1.317e-05, eta: 0:35:47, time: 0.400, data_time: 0.051, memory: 15394, decode.loss_depth: 0.0413, loss: 0.0413, grad_norm: 0.4400
2022-04-03 20:45:01,517 - depth - INFO - Epoch [21][100/1514]	lr: 1.296e-05, eta: 0:35:30, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0412, loss: 0.0412, grad_norm: 0.4352
2022-04-03 20:45:19,409 - depth - INFO - Epoch [21][150/1514]	lr: 1.276e-05, eta: 0:35:12, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0420, loss: 0.0420, grad_norm: 0.5705
2022-04-03 20:45:37,298 - depth - INFO - Epoch [21][200/1514]	lr: 1.255e-05, eta: 0:34:54, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0426, loss: 0.0426, grad_norm: 0.5344
2022-04-03 20:45:55,192 - depth - INFO - Epoch [21][250/1514]	lr: 1.235e-05, eta: 0:34:36, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0411, loss: 0.0411, grad_norm: 0.5097
2022-04-03 20:46:13,037 - depth - INFO - Epoch [21][300/1514]	lr: 1.215e-05, eta: 0:34:18, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0395, loss: 0.0395, grad_norm: 0.3508
2022-04-03 20:46:30,916 - depth - INFO - Epoch [21][350/1514]	lr: 1.195e-05, eta: 0:34:00, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0395, loss: 0.0395, grad_norm: 0.4007
2022-04-03 20:46:48,743 - depth - INFO - Epoch [21][400/1514]	lr: 1.175e-05, eta: 0:33:42, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0404, loss: 0.0404, grad_norm: 0.5221
2022-04-03 20:47:06,571 - depth - INFO - Epoch [21][450/1514]	lr: 1.155e-05, eta: 0:33:24, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0410, loss: 0.0410, grad_norm: 0.4588
2022-04-03 20:47:24,457 - depth - INFO - Epoch [21][500/1514]	lr: 1.135e-05, eta: 0:33:06, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0406, loss: 0.0406, grad_norm: 0.4396
2022-04-03 20:47:42,411 - depth - INFO - Epoch [21][550/1514]	lr: 1.116e-05, eta: 0:32:49, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0412, loss: 0.0412, grad_norm: 0.3328
2022-04-03 20:48:00,293 - depth - INFO - Epoch [21][600/1514]	lr: 1.097e-05, eta: 0:32:31, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0406, loss: 0.0406, grad_norm: 0.3330
2022-04-03 20:48:18,187 - depth - INFO - Epoch [21][650/1514]	lr: 1.077e-05, eta: 0:32:13, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0402, loss: 0.0402, grad_norm: 0.3416
2022-04-03 20:48:36,016 - depth - INFO - Epoch [21][700/1514]	lr: 1.058e-05, eta: 0:31:55, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0408, loss: 0.0408, grad_norm: 0.5766
2022-04-03 20:48:53,925 - depth - INFO - Epoch [21][750/1514]	lr: 1.039e-05, eta: 0:31:37, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0400, loss: 0.0400, grad_norm: 0.4370
2022-04-03 20:49:11,762 - depth - INFO - Epoch [21][800/1514]	lr: 1.021e-05, eta: 0:31:19, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0402, loss: 0.0402, grad_norm: 0.3237
2022-04-03 20:49:29,610 - depth - INFO - Epoch [21][850/1514]	lr: 1.002e-05, eta: 0:31:01, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0393, loss: 0.0393, grad_norm: 0.3360
2022-04-03 20:49:47,491 - depth - INFO - Epoch [21][900/1514]	lr: 9.837e-06, eta: 0:30:43, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0395, loss: 0.0395, grad_norm: 0.3025
2022-04-03 20:50:05,364 - depth - INFO - Epoch [21][950/1514]	lr: 9.654e-06, eta: 0:30:26, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0405, loss: 0.0405, grad_norm: 0.3140
2022-04-03 20:50:23,236 - depth - INFO - Epoch [21][1000/1514]	lr: 9.473e-06, eta: 0:30:08, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0400, loss: 0.0400, grad_norm: 0.2678
2022-04-03 20:50:41,135 - depth - INFO - Epoch [21][1050/1514]	lr: 9.293e-06, eta: 0:29:50, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0392, loss: 0.0392, grad_norm: 0.3361
2022-04-03 20:50:59,015 - depth - INFO - Epoch [21][1100/1514]	lr: 9.115e-06, eta: 0:29:32, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0406, loss: 0.0406, grad_norm: 0.3426
2022-04-03 20:51:16,893 - depth - INFO - Epoch [21][1150/1514]	lr: 8.939e-06, eta: 0:29:14, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0411, loss: 0.0411, grad_norm: 0.3893
2022-04-03 20:51:34,780 - depth - INFO - Epoch [21][1200/1514]	lr: 8.764e-06, eta: 0:28:56, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0395, loss: 0.0395, grad_norm: 0.3622
2022-04-03 20:51:52,642 - depth - INFO - Epoch [21][1250/1514]	lr: 8.590e-06, eta: 0:28:38, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0404, loss: 0.0404, grad_norm: 0.3307
2022-04-03 20:52:10,507 - depth - INFO - Epoch [21][1300/1514]	lr: 8.418e-06, eta: 0:28:20, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0402, loss: 0.0402, grad_norm: 0.3366
2022-04-03 20:52:28,385 - depth - INFO - Epoch [21][1350/1514]	lr: 8.248e-06, eta: 0:28:03, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0400, loss: 0.0400, grad_norm: 0.3704
2022-04-03 20:52:46,287 - depth - INFO - Epoch [21][1400/1514]	lr: 8.079e-06, eta: 0:27:45, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0401, loss: 0.0401, grad_norm: 0.4300
2022-04-03 20:53:04,178 - depth - INFO - Epoch [21][1450/1514]	lr: 7.912e-06, eta: 0:27:27, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0392, loss: 0.0392, grad_norm: 0.2946
2022-04-03 20:53:22,051 - depth - INFO - Epoch [21][1500/1514]	lr: 7.747e-06, eta: 0:27:09, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0389, loss: 0.0389, grad_norm: 0.2808
2022-04-03 20:53:27,147 - depth - INFO - Saving checkpoint at 21 epochs
2022-04-03 20:53:47,787 - depth - INFO - Epoch [22][50/1514]	lr: 7.537e-06, eta: 0:26:46, time: 0.400, data_time: 0.051, memory: 15394, decode.loss_depth: 0.0398, loss: 0.0398, grad_norm: 0.3630
2022-04-03 20:54:05,619 - depth - INFO - Epoch [22][100/1514]	lr: 7.376e-06, eta: 0:26:28, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0401, loss: 0.0401, grad_norm: 0.3212
2022-04-03 20:54:23,466 - depth - INFO - Epoch [22][150/1514]	lr: 7.215e-06, eta: 0:26:10, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0403, loss: 0.0403, grad_norm: 0.3540
2022-04-03 20:54:41,319 - depth - INFO - Epoch [22][200/1514]	lr: 7.057e-06, eta: 0:25:52, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0413, loss: 0.0413, grad_norm: 0.3062
2022-04-03 20:54:59,182 - depth - INFO - Epoch [22][250/1514]	lr: 6.900e-06, eta: 0:25:34, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0399, loss: 0.0399, grad_norm: 0.3508
2022-04-03 20:55:17,037 - depth - INFO - Epoch [22][300/1514]	lr: 6.745e-06, eta: 0:25:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0389, loss: 0.0389, grad_norm: 0.2974
2022-04-03 20:55:34,885 - depth - INFO - Epoch [22][350/1514]	lr: 6.591e-06, eta: 0:24:58, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0383, loss: 0.0383, grad_norm: 0.3898
2022-04-03 20:55:52,750 - depth - INFO - Epoch [22][400/1514]	lr: 6.439e-06, eta: 0:24:40, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0394, loss: 0.0394, grad_norm: 0.5406
2022-04-03 20:56:10,575 - depth - INFO - Epoch [22][450/1514]	lr: 6.289e-06, eta: 0:24:23, time: 0.357, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0400, loss: 0.0400, grad_norm: 0.4088
2022-04-03 20:56:28,445 - depth - INFO - Epoch [22][500/1514]	lr: 6.140e-06, eta: 0:24:05, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0395, loss: 0.0395, grad_norm: 0.3080
2022-04-03 20:56:46,326 - depth - INFO - Epoch [22][550/1514]	lr: 5.993e-06, eta: 0:23:47, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0407, loss: 0.0407, grad_norm: 0.4089
2022-04-03 20:57:04,206 - depth - INFO - Epoch [22][600/1514]	lr: 5.848e-06, eta: 0:23:29, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0396, loss: 0.0396, grad_norm: 0.3357
2022-04-03 20:57:22,068 - depth - INFO - Epoch [22][650/1514]	lr: 5.705e-06, eta: 0:23:11, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0396, loss: 0.0396, grad_norm: 0.2873
2022-04-03 20:57:39,914 - depth - INFO - Epoch [22][700/1514]	lr: 5.563e-06, eta: 0:22:53, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0393, loss: 0.0393, grad_norm: 0.3227
2022-04-03 20:57:57,816 - depth - INFO - Epoch [22][750/1514]	lr: 5.422e-06, eta: 0:22:35, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0391, loss: 0.0391, grad_norm: 0.3323
2022-04-03 20:58:15,658 - depth - INFO - Epoch [22][800/1514]	lr: 5.284e-06, eta: 0:22:17, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0391, loss: 0.0391, grad_norm: 0.3020
2022-04-03 20:58:33,556 - depth - INFO - Epoch [22][850/1514]	lr: 5.147e-06, eta: 0:22:00, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0383, loss: 0.0383, grad_norm: 0.2715
2022-04-03 20:58:51,418 - depth - INFO - Epoch [22][900/1514]	lr: 5.012e-06, eta: 0:21:42, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0386, loss: 0.0386, grad_norm: 0.2613
2022-04-03 20:59:09,276 - depth - INFO - Epoch [22][950/1514]	lr: 4.879e-06, eta: 0:21:24, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0397, loss: 0.0397, grad_norm: 0.3828
2022-04-03 20:59:27,139 - depth - INFO - Epoch [22][1000/1514]	lr: 4.747e-06, eta: 0:21:06, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0392, loss: 0.0392, grad_norm: 0.3563
2022-04-03 20:59:44,980 - depth - INFO - Epoch [22][1050/1514]	lr: 4.617e-06, eta: 0:20:48, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0386, loss: 0.0386, grad_norm: 0.2891
2022-04-03 21:00:02,846 - depth - INFO - Epoch [22][1100/1514]	lr: 4.489e-06, eta: 0:20:30, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0397, loss: 0.0397, grad_norm: 0.3415
2022-04-03 21:00:20,737 - depth - INFO - Epoch [22][1150/1514]	lr: 4.363e-06, eta: 0:20:12, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0400, loss: 0.0400, grad_norm: 0.2916
2022-04-03 21:00:38,626 - depth - INFO - Epoch [22][1200/1514]	lr: 4.238e-06, eta: 0:19:54, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.3307
2022-04-03 21:00:56,563 - depth - INFO - Epoch [22][1250/1514]	lr: 4.115e-06, eta: 0:19:36, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0397, loss: 0.0397, grad_norm: 0.2545
2022-04-03 21:01:14,480 - depth - INFO - Epoch [22][1300/1514]	lr: 3.994e-06, eta: 0:19:19, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0393, loss: 0.0393, grad_norm: 0.2584
2022-04-03 21:01:32,382 - depth - INFO - Epoch [22][1350/1514]	lr: 3.874e-06, eta: 0:19:01, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0388, loss: 0.0388, grad_norm: 0.2824
2022-04-03 21:01:50,326 - depth - INFO - Epoch [22][1400/1514]	lr: 3.757e-06, eta: 0:18:43, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0391, loss: 0.0391, grad_norm: 0.3350
2022-04-03 21:02:08,211 - depth - INFO - Epoch [22][1450/1514]	lr: 3.641e-06, eta: 0:18:25, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0382, loss: 0.0382, grad_norm: 0.3038
2022-04-03 21:02:26,116 - depth - INFO - Epoch [22][1500/1514]	lr: 3.527e-06, eta: 0:18:07, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0383, loss: 0.0383, grad_norm: 0.3512
2022-04-03 21:02:31,214 - depth - INFO - Saving checkpoint at 22 epochs
2022-04-03 21:02:51,823 - depth - INFO - Epoch [23][50/1514]	lr: 3.383e-06, eta: 0:17:44, time: 0.399, data_time: 0.049, memory: 15394, decode.loss_depth: 0.0388, loss: 0.0388, grad_norm: 0.3408
2022-04-03 21:03:09,703 - depth - INFO - Epoch [23][100/1514]	lr: 3.273e-06, eta: 0:17:26, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0393, loss: 0.0393, grad_norm: 0.2968
2022-04-03 21:03:27,617 - depth - INFO - Epoch [23][150/1514]	lr: 3.165e-06, eta: 0:17:08, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0397, loss: 0.0397, grad_norm: 0.2976
2022-04-03 21:03:45,536 - depth - INFO - Epoch [23][200/1514]	lr: 3.058e-06, eta: 0:16:50, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0404, loss: 0.0404, grad_norm: 0.3278
2022-04-03 21:04:03,419 - depth - INFO - Epoch [23][250/1514]	lr: 2.953e-06, eta: 0:16:32, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0389, loss: 0.0389, grad_norm: 0.3202
2022-04-03 21:04:21,347 - depth - INFO - Epoch [23][300/1514]	lr: 2.850e-06, eta: 0:16:15, time: 0.359, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0379, loss: 0.0379, grad_norm: 0.3199
2022-04-03 21:04:39,237 - depth - INFO - Epoch [23][350/1514]	lr: 2.749e-06, eta: 0:15:57, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0376, loss: 0.0376, grad_norm: 0.3667
2022-04-03 21:04:57,085 - depth - INFO - Epoch [23][400/1514]	lr: 2.650e-06, eta: 0:15:39, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.3593
2022-04-03 21:05:14,892 - depth - INFO - Epoch [23][450/1514]	lr: 2.552e-06, eta: 0:15:21, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.2793
2022-04-03 21:05:32,765 - depth - INFO - Epoch [23][500/1514]	lr: 2.457e-06, eta: 0:15:03, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0390, loss: 0.0390, grad_norm: 0.2919
2022-04-03 21:05:50,660 - depth - INFO - Epoch [23][550/1514]	lr: 2.363e-06, eta: 0:14:45, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0399, loss: 0.0399, grad_norm: 0.2956
2022-04-03 21:06:08,556 - depth - INFO - Epoch [23][600/1514]	lr: 2.271e-06, eta: 0:14:27, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0386, loss: 0.0386, grad_norm: 0.2841
2022-04-03 21:06:26,420 - depth - INFO - Epoch [23][650/1514]	lr: 2.180e-06, eta: 0:14:10, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0386, loss: 0.0386, grad_norm: 0.2783
2022-04-03 21:06:44,236 - depth - INFO - Epoch [23][700/1514]	lr: 2.092e-06, eta: 0:13:52, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0389, loss: 0.0389, grad_norm: 0.2949
2022-04-03 21:07:02,125 - depth - INFO - Epoch [23][750/1514]	lr: 2.005e-06, eta: 0:13:34, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0383, loss: 0.0383, grad_norm: 0.2273
2022-04-03 21:07:19,966 - depth - INFO - Epoch [23][800/1514]	lr: 1.921e-06, eta: 0:13:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.2622
2022-04-03 21:07:37,828 - depth - INFO - Epoch [23][850/1514]	lr: 1.838e-06, eta: 0:12:58, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0378, loss: 0.0378, grad_norm: 0.3122
2022-04-03 21:07:55,664 - depth - INFO - Epoch [23][900/1514]	lr: 1.756e-06, eta: 0:12:40, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0381, loss: 0.0381, grad_norm: 0.2848
2022-04-03 21:08:13,518 - depth - INFO - Epoch [23][950/1514]	lr: 1.677e-06, eta: 0:12:22, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.2465
2022-04-03 21:08:31,370 - depth - INFO - Epoch [23][1000/1514]	lr: 1.600e-06, eta: 0:12:04, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0384, loss: 0.0384, grad_norm: 0.3017
2022-04-03 21:08:49,234 - depth - INFO - Epoch [23][1050/1514]	lr: 1.524e-06, eta: 0:11:47, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0379, loss: 0.0379, grad_norm: 0.2666
2022-04-03 21:09:07,116 - depth - INFO - Epoch [23][1100/1514]	lr: 1.450e-06, eta: 0:11:29, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0394, loss: 0.0394, grad_norm: 0.2984
2022-04-03 21:09:24,977 - depth - INFO - Epoch [23][1150/1514]	lr: 1.379e-06, eta: 0:11:11, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0394, loss: 0.0394, grad_norm: 0.2653
2022-04-03 21:09:42,903 - depth - INFO - Epoch [23][1200/1514]	lr: 1.309e-06, eta: 0:10:53, time: 0.359, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0379, loss: 0.0379, grad_norm: 0.2480
2022-04-03 21:10:00,777 - depth - INFO - Epoch [23][1250/1514]	lr: 1.240e-06, eta: 0:10:35, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.2198
2022-04-03 21:10:18,679 - depth - INFO - Epoch [23][1300/1514]	lr: 1.174e-06, eta: 0:10:17, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0389, loss: 0.0389, grad_norm: 0.2758
2022-04-03 21:10:36,543 - depth - INFO - Epoch [23][1350/1514]	lr: 1.110e-06, eta: 0:09:59, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0384, loss: 0.0384, grad_norm: 0.2707
2022-04-03 21:10:54,465 - depth - INFO - Epoch [23][1400/1514]	lr: 1.047e-06, eta: 0:09:41, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.2813
2022-04-03 21:11:12,335 - depth - INFO - Epoch [23][1450/1514]	lr: 9.863e-07, eta: 0:09:24, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0381, loss: 0.0381, grad_norm: 0.2634
2022-04-03 21:11:30,205 - depth - INFO - Epoch [23][1500/1514]	lr: 9.275e-07, eta: 0:09:06, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0377, loss: 0.0377, grad_norm: 0.2716
2022-04-03 21:11:35,292 - depth - INFO - Saving checkpoint at 23 epochs
2022-04-03 21:11:55,896 - depth - INFO - Epoch [24][50/1514]	lr: 8.549e-07, eta: 0:08:43, time: 0.399, data_time: 0.050, memory: 15394, decode.loss_depth: 0.0384, loss: 0.0384, grad_norm: 0.2951
2022-04-03 21:12:13,766 - depth - INFO - Epoch [24][100/1514]	lr: 8.003e-07, eta: 0:08:25, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0390, loss: 0.0390, grad_norm: 0.2484
2022-04-03 21:12:31,655 - depth - INFO - Epoch [24][150/1514]	lr: 7.476e-07, eta: 0:08:07, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0388, loss: 0.0388, grad_norm: 0.2463
2022-04-03 21:12:49,546 - depth - INFO - Epoch [24][200/1514]	lr: 6.968e-07, eta: 0:07:49, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0405, loss: 0.0405, grad_norm: 0.2714
2022-04-03 21:13:07,428 - depth - INFO - Epoch [24][250/1514]	lr: 6.479e-07, eta: 0:07:31, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.2560
2022-04-03 21:13:25,316 - depth - INFO - Epoch [24][300/1514]	lr: 6.008e-07, eta: 0:07:13, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0374, loss: 0.0374, grad_norm: 0.2685
2022-04-03 21:13:43,178 - depth - INFO - Epoch [24][350/1514]	lr: 5.556e-07, eta: 0:06:55, time: 0.357, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0372, loss: 0.0372, grad_norm: 0.2729
2022-04-03 21:14:01,083 - depth - INFO - Epoch [24][400/1514]	lr: 5.124e-07, eta: 0:06:38, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0379, loss: 0.0379, grad_norm: 0.3154
2022-04-03 21:14:18,880 - depth - INFO - Epoch [24][450/1514]	lr: 4.710e-07, eta: 0:06:20, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.2244
2022-04-03 21:14:36,756 - depth - INFO - Epoch [24][500/1514]	lr: 4.315e-07, eta: 0:06:02, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.2741
2022-04-03 21:14:54,652 - depth - INFO - Epoch [24][550/1514]	lr: 3.939e-07, eta: 0:05:44, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0395, loss: 0.0395, grad_norm: 0.2722
2022-04-03 21:15:12,564 - depth - INFO - Epoch [24][600/1514]	lr: 3.581e-07, eta: 0:05:26, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0383, loss: 0.0383, grad_norm: 0.2498
2022-04-03 21:15:30,447 - depth - INFO - Epoch [24][650/1514]	lr: 3.243e-07, eta: 0:05:08, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.2494
2022-04-03 21:15:48,306 - depth - INFO - Epoch [24][700/1514]	lr: 2.924e-07, eta: 0:04:50, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0384, loss: 0.0384, grad_norm: 0.2760
2022-04-03 21:16:06,192 - depth - INFO - Epoch [24][750/1514]	lr: 2.624e-07, eta: 0:04:33, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0380, loss: 0.0380, grad_norm: 0.2240
2022-04-03 21:16:24,014 - depth - INFO - Epoch [24][800/1514]	lr: 2.342e-07, eta: 0:04:15, time: 0.356, data_time: 0.007, memory: 15394, decode.loss_depth: 0.0383, loss: 0.0383, grad_norm: 0.2568
2022-04-03 21:16:41,872 - depth - INFO - Epoch [24][850/1514]	lr: 2.080e-07, eta: 0:03:57, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0375, loss: 0.0375, grad_norm: 0.2850
2022-04-03 21:16:59,753 - depth - INFO - Epoch [24][900/1514]	lr: 1.837e-07, eta: 0:03:39, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0378, loss: 0.0378, grad_norm: 0.2237
2022-04-03 21:17:17,646 - depth - INFO - Epoch [24][950/1514]	lr: 1.612e-07, eta: 0:03:21, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0388, loss: 0.0388, grad_norm: 0.2713
2022-04-03 21:17:35,542 - depth - INFO - Epoch [24][1000/1514]	lr: 1.407e-07, eta: 0:03:03, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.2271
2022-04-03 21:17:53,397 - depth - INFO - Epoch [24][1050/1514]	lr: 1.221e-07, eta: 0:02:45, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0375, loss: 0.0375, grad_norm: 0.2541
2022-04-03 21:18:11,239 - depth - INFO - Epoch [24][1100/1514]	lr: 1.053e-07, eta: 0:02:27, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0387, loss: 0.0387, grad_norm: 0.2561
2022-04-03 21:18:29,134 - depth - INFO - Epoch [24][1150/1514]	lr: 9.050e-08, eta: 0:02:10, time: 0.358, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0391, loss: 0.0391, grad_norm: 0.2375
2022-04-03 21:18:47,034 - depth - INFO - Epoch [24][1200/1514]	lr: 7.758e-08, eta: 0:01:52, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0376, loss: 0.0376, grad_norm: 0.2516
2022-04-03 21:19:04,872 - depth - INFO - Epoch [24][1250/1514]	lr: 6.657e-08, eta: 0:01:34, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0389, loss: 0.0389, grad_norm: 0.2244
2022-04-03 21:19:22,710 - depth - INFO - Epoch [24][1300/1514]	lr: 5.746e-08, eta: 0:01:16, time: 0.357, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0385, loss: 0.0385, grad_norm: 0.2259
2022-04-03 21:19:40,585 - depth - INFO - Epoch [24][1350/1514]	lr: 5.025e-08, eta: 0:00:58, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0384, loss: 0.0384, grad_norm: 0.2811
2022-04-03 21:19:58,470 - depth - INFO - Epoch [24][1400/1514]	lr: 4.495e-08, eta: 0:00:40, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0382, loss: 0.0382, grad_norm: 0.2172
2022-04-03 21:20:16,372 - depth - INFO - Epoch [24][1450/1514]	lr: 4.156e-08, eta: 0:00:22, time: 0.358, data_time: 0.009, memory: 15394, decode.loss_depth: 0.0374, loss: 0.0374, grad_norm: 0.2297
2022-04-03 21:20:34,188 - depth - INFO - Epoch [24][1500/1514]	lr: 4.007e-08, eta: 0:00:05, time: 0.356, data_time: 0.008, memory: 15394, decode.loss_depth: 0.0377, loss: 0.0377, grad_norm: 0.2656
2022-04-03 21:20:39,308 - depth - INFO - Saving checkpoint at 24 epochs
2022-04-03 21:20:58,785 - depth - INFO - Summary:
2022-04-03 21:20:58,785 - depth - INFO - 
+--------+--------+--------+---------+--------+--------+----------+---------+--------+
|   a1   |   a2   |   a3   | abs_rel |  rmse  | log_10 | rmse_log |  silog  | sq_rel |
+--------+--------+--------+---------+--------+--------+----------+---------+--------+
| 0.8708 | 0.9784 | 0.9956 |  0.1135 | 0.4033 | 0.0488 |  0.1458  | 11.7313 | 0.0671 |
+--------+--------+--------+---------+--------+--------+----------+---------+--------+
2022-04-03 21:20:58,785 - depth - INFO - Exp name: bts_r50_nyu_24e.py
2022-04-03 21:20:58,785 - depth - INFO - Epoch(val) [24][327]	a1: 0.8708, a2: 0.9784, a3: 0.9956, abs_rel: 0.11352112144231796, rmse: 0.4032611846923828, log_10: 0.048821333795785904, rmse_log: 0.14579059183597565, silog: 11.7313, sq_rel: 0.0671207383275032
